{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "from typing import Optional, List, Dict, Union\n",
    "from itertools import combinations\n",
    "from math import ceil, floor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from cycler import cycler\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import to_hex\n",
    "\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from book_processor.Book import PROJ_ROOT\n",
    "\n",
    "\n",
    "NEW_GENRES = [\"Adventure_Stories\", \"Fiction\", \"Historical_Fiction\", \n",
    "          \"Love_Stories\", \"Mystery\", \"Poetry\", \"Science_Fiction\", \"Short_Stories\"]\n",
    "\n",
    "GENRE_COMBS = [(c1, c2) for c1, c2 in combinations(NEW_GENRES, 2)]\n",
    "\n",
    "scale = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def display_df(df: pd.DataFrame, header: Optional[str] = None, max_rows: Optional[int] = None, \n",
    "               add_break: bool = False, formatters: Optional[Dict] = None, index: bool = False):\n",
    "    html = \"\"\n",
    "    if header is not None:\n",
    "        html += header\n",
    "        \n",
    "    if format is not None:\n",
    "        html += df.to_html(index=index, max_rows=max_rows, formatters=formatters)\n",
    "    else:\n",
    "        html += df.to_html(index=index, max_rows=max_rows)\n",
    "        \n",
    "    if add_break:\n",
    "        html += \"<br>\"\n",
    "    display(HTML(html))\n",
    "    \n",
    "\n",
    "def setup_axis(ax, xmin: Optional[Union[int, float]] = 0, xmax: Optional[Union[int, float]] = 1,\n",
    "               ymin: Union[int, float] = 0, ymax: Union[int, float] = 1,\n",
    "               xlabel: str = \"\", ylabel: str = \"\", **kwargs):\n",
    "    \"\"\"\n",
    "    - xmajor: int = 20\n",
    "    - xminor: int = 100\n",
    "    - ymajor: int = 20\n",
    "    - yminor: int = 100\n",
    "    - x_ticklabels: List = None\n",
    "    - x_ticklabel_size: Union[int, float] = 20\n",
    "    - y_ticklabel_size: Union[int, float] = 24\n",
    "    - xlabel_size: Union[int, float] = 28\n",
    "    - xlabel_pad: Union[int, float] = 20\n",
    "    - ylabel_size: Union[int, float] = 32\n",
    "    - ylabel_pad: Union[int, float] = 30\n",
    "    - left: Union[int, float] = None\n",
    "    - right: Union[int, float] = None\n",
    "    - bottom: Union[int, float] = None\n",
    "    - top: Union[int, float] = None\n",
    "    - grid: str = \"--\"\n",
    "    - minor_grid: str = None\n",
    "    \"\"\"\n",
    "    \n",
    "    if \"x_ticklabels\" not in kwargs and xmin is not None:\n",
    "        if xmin < 0:\n",
    "            xmajor = kwargs.get(\"xmajor\", xmax * 4)\n",
    "            ax.set_xticks(np.arange(xmin if xmajor >= 40 else 0, xmax + 1, xmax / xmajor))\n",
    "            \n",
    "            xminor = kwargs.get(\"xminor\", xmajor * 10)\n",
    "            ax.set_xticks(np.arange(xmin, xmax + 1, xmax / xminor), minor=True)\n",
    "        else:\n",
    "            ax.set_xticks(np.linspace(xmin, xmax, kwargs.get(\"xmajor\", 20) + 1))\n",
    "            ax.set_xticks(np.linspace(xmin, xmax, kwargs.get(\"xminor\", 100) + 1), minor=True)\n",
    "    elif \"x_ticklabels\" in kwargs:\n",
    "        ax.set_xticks(np.arange(xmin, len(kwargs[\"x_ticklabels\"])))\n",
    "        ax.set_xticklabels(kwargs[\"x_ticklabels\"])\n",
    "    \n",
    "    ax.set_yticks(np.linspace(ymin, ymax, kwargs.get(\"ymajor\", 20) + 1))\n",
    "    ax.set_yticks(np.linspace(ymin, ymax, kwargs.get(\"yminor\", 100) + 1), minor=True)\n",
    "    \n",
    "    ax.tick_params(axis=\"x\", labelsize=kwargs.get(\"x_ticklabel_size\", 20))\n",
    "    ax.tick_params(axis=\"y\", labelsize=kwargs.get(\"y_ticklabel_size\", 24))\n",
    "    \n",
    "    xlabel_size = kwargs.get(\"xlabel_size\", 0 if xlabel == \"\" else 28)\n",
    "    xlabel_pad = kwargs.get(\"xlabel_pad\", None if xlabel == \"\" else 20)\n",
    "    ax.set_xlabel(xlabel, fontsize=xlabel_size, labelpad=xlabel_pad)\n",
    "    ax.set_ylabel(ylabel, fontsize=kwargs.get(\"ylabel_size\", 32), labelpad=kwargs.get(\"ylabel_pad\", 30))\n",
    "    \n",
    "    if \"left\" in kwargs:\n",
    "        ax.set_xlim(left=kwargs[\"left\"])\n",
    "    if \"right\" in kwargs:\n",
    "        ax.set_xlim(right=kwargs[\"right\"])\n",
    "    if \"bottom\" in kwargs:\n",
    "        ax.set_ylim(bottom=kwargs[\"bottom\"])\n",
    "    if \"top\" in kwargs:\n",
    "        ax.set_ylim(top=kwargs[\"top\"])\n",
    "    \n",
    "    ax.grid(linestyle=kwargs.get(\"grid\", \"--\"))\n",
    "    ax.grid(linestyle=kwargs.get(\"minor_grid\", \"none\"), which=\"minor\")\n",
    "\n",
    "\n",
    "def auto_label(ax, fontsize: int = 12):\n",
    "    rects = ax.patches\n",
    "    (y_bottom, y_top) = ax.get_ylim()\n",
    "    y_height = y_top - y_bottom + 0.05\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        p_height = (height / y_height)\n",
    "        if p_height > 0.95:\n",
    "            label_position = height - (y_height * 0.05)\n",
    "        else:\n",
    "            label_position = height + (y_height * 0.01)\n",
    "        if label_position > 0.1:\n",
    "            ax.text(rect.get_x() + rect.get_width() / 2., label_position, \n",
    "                    \"{0:.3f}\".format(height), ha='center', va='bottom', fontsize=fontsize)\n",
    "            \n",
    "\n",
    "def process_and_scale(data: Union[List, pd.DataFrame], n_cols: int = 5, book_nums: Optional[pd.Series] = None):\n",
    "    if isinstance(data, List):\n",
    "        data_df = pd.DataFrame(data).fillna(0)\n",
    "    else:\n",
    "        data_df = data.reset_index(drop=True)\n",
    "    \n",
    "    if book_nums is not None:\n",
    "        data_df.insert(0, \"Book #\", book_nums.reset_index(drop=True))\n",
    "        data_df.rename(columns={\"_genre\": \"@Genre\", \"_outcome\": \"@Outcome\"}, inplace=True)\n",
    "    \n",
    "    nominal = data_df[[\"Book #\", \"@Genre\", \"@Outcome\"]]\n",
    "    data_df.drop(columns=[\"Book #\", \"@Genre\", \"@Outcome\"], inplace=True)\n",
    "    data_df_scaled = scale.fit_transform(data_df)\n",
    "    data_df_scaled = pd.DataFrame(data_df_scaled, columns=data_df.columns)\n",
    "    data_df_scaled[\"@Outcome\"] = nominal[\"@Outcome\"]\n",
    "    data_df_scaled.insert(0, \"@Genre\", nominal[\"@Genre\"])\n",
    "    data_df_scaled.insert(0, \"Book #\", nominal[\"Book #\"])\n",
    "    to_display = get_display_df(data_df_scaled, n_cols)\n",
    "    \n",
    "    return data_df_scaled, to_display\n",
    "\n",
    "\n",
    "def get_display_df(df: pd.DataFrame, n_cols: int = 5):\n",
    "    to_display = df.iloc[:, :n_cols].copy()\n",
    "    to_display[\"...\"] = \"...\"\n",
    "    to_display = pd.concat([to_display, df.iloc[:, -n_cols:]], axis=1)\n",
    "    return to_display\n",
    "\n",
    "\n",
    "def remove_numbers(df: pd.DataFrame):\n",
    "    drop_cols = [c for c in df.columns if re.match(\"[A-Za-z]*\\d+[A-Za-z]*\", c, re.IGNORECASE)]\n",
    "    dropped = df.drop(columns=drop_cols) \n",
    "    return dropped\n",
    "\n",
    "\n",
    "def tfi_ngram(df_temp: pd.DataFrame, uni: bool = False, bi: bool = False):\n",
    "    if uni:\n",
    "        tfi_ngram_df_vect = CountVectorizer(analyzer=\"word\")\n",
    "    elif bi:\n",
    "        tfi_ngram_df_vect = CountVectorizer(analyzer=\"word\", ngram_range=(2,2))\n",
    "        \n",
    "    tfi_ngram_df_vect.fit(df_temp[\"first_1k\"])\n",
    "    tfi_ngram_data = tfi_ngram_df_vect.transform(df_temp[\"first_1k\"])\n",
    "    tfi_ngram_data = pd.DataFrame(tfi_ngram_data.todense(), columns=tfi_ngram_df_vect.get_feature_names())\n",
    "    tfi_ngram_data = remove_numbers(tfi_ngram_data)\n",
    "    return tfi_ngram_data\n",
    "\n",
    "\n",
    "def process_weights(model_weights: Dict, display: bool = True):\n",
    "    for key, weights in model_weights.items():\n",
    "        model_weights[key] = pd.concat(weights)\n",
    "        model_weights[key].reset_index(drop=True, inplace=True)\n",
    "        model_weights[key] = model_weights[key].mean(axis=0).reset_index()\n",
    "        model_weights[key].columns = [\"Feature\", \"Weight\"]\n",
    "        model_weights[key] = model_weights[key].sort_values(by=[\"Weight\"], ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        if display:\n",
    "            display_df(model_weights[key], f\"<h4>{key} Feature Weights</h4>\", 10, True)\n",
    "            \n",
    "    return model_weights\n",
    "\n",
    "\n",
    "def predict_success(model_df: pd.DataFrame, model_name: str, genre_list: List[str] = NEW_GENRES, **kwargs):\n",
    "    \"\"\"\n",
    "    - add_to_acc: Dict = None\n",
    "    - disp_acc = True\n",
    "    - disp_weights = True\n",
    "    - searching = False\n",
    "    - show_pbar = True\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    weights = {genre: [] for genre in genre_list}\n",
    "\n",
    "    if kwargs.get(\"show_pbar\", True):\n",
    "        display(HTML(f\"<h4>Predicting book success with {model_name} data...</h4>\"))\n",
    "        bar_length = len(genre_list) * 5\n",
    "        with tqdm(total=bar_length) as pbar:\n",
    "            _predict_success(model_df, model_name, accuracies, weights, genre_list, pbar, **kwargs)\n",
    "    else:\n",
    "        _predict_success(model_df, model_name, accuracies, weights, genre_list, **kwargs)\n",
    "        \n",
    "    accuracies = pd.DataFrame(accuracies)\n",
    "    weights = process_weights(weights, display=kwargs.get(\"disp_weights\", True))\n",
    "    if kwargs.get(\"add_to_acc\", None) is not None:\n",
    "        add_to_acc.update({model_name: accuracies})\n",
    "\n",
    "    accuracies = accuracies.append({\"Genre\": \"Average\", \"Accuracy\": accuracies[\"Accuracy\"].mean()}, ignore_index=True)\n",
    "    if kwargs.get(\"disp_acc\", True):\n",
    "        display_df(accuracies, f\"<h4>{model_name} Accuracies by Genre</h4>\")\n",
    "\n",
    "    return accuracies, weights\n",
    "\n",
    "\n",
    "def _predict_success(model_df: pd.DataFrame, model_name: str, accs: List, ws: Dict, genre_list: List[str] = NEW_GENRES, pbar: Optional = None, **kwargs):\n",
    "    \"\"\"\n",
    "    - searching = False\n",
    "    \"\"\"\n",
    "    for genre in genre_list:\n",
    "        if pbar is not None:\n",
    "            pbar.set_postfix_str(f\" -- {genre}\")\n",
    "        \n",
    "        df_temp = model_df[model_df[\"@Genre\"] == genre]\n",
    "        mean_acc = _train_test(df_temp, model_name, ws, genre, \"@Outcome\", pbar, **kwargs)\n",
    "\n",
    "        accuracy = np.array(mean_acc).mean()\n",
    "        accs.append({\"Genre\": genre, \"Accuracy\": accuracy})\n",
    "\n",
    "\n",
    "def predict_genre(model_df: pd.DataFrame, model_name: str, how: str = \"one_v_one\", genre_list: List = GENRE_COMBS, **kwargs):\n",
    "    \"\"\"\n",
    "    - add_to_acc: Dict = None\n",
    "    - disp_acc = True\n",
    "    - disp_weights = True\n",
    "    - searching = False\n",
    "    - show_pbar = True\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    weights = {genre: [] for genre in genre_list}\n",
    "\n",
    "    if kwargs.get(\"show_pbar\", True):\n",
    "        display(HTML(f\"<h4>Performing {how} binary genre prediction with {model_name} data...</h4>\"))\n",
    "        bar_length = len(genre_list) * 5\n",
    "        with tqdm(total=bar_length) as pbar:\n",
    "            globals()[how](model_df, model_name, accuracies, weights, genre_list, pbar, **kwargs)\n",
    "    \n",
    "    else:\n",
    "        globals()[how](model_df, model_name, accuracies, weights, genre_list, **kwargs)\n",
    "\n",
    "    accuracies = pd.DataFrame(accuracies)\n",
    "    weights = process_weights(weights, display=kwargs.get(\"disp_weights\", True))\n",
    "    if kwargs.get(\"add_to_acc\", None) is not None:\n",
    "        add_to_acc.update({model_name: accuracies})\n",
    "\n",
    "    accuracies = accuracies.append({\"Genre\": \"Average\", \"Accuracy\": accuracies[\"Accuracy\"].mean()}, ignore_index=True)\n",
    "    if kwargs.get(\"disp_acc\", True):\n",
    "        display_df(accuracies, f\"<h4>{model_name} Accuracies by Genre</h4>\")\n",
    "\n",
    "    return accuracies, weights\n",
    "\n",
    "def one_v_one(model_df: pd.DataFrame, model_name: str, accs: List, ws: Dict, genre_list: List, pbar: Optional = None, **kwargs):\n",
    "    for g1, g2 in genre_list:\n",
    "        if pbar is not None:\n",
    "            pbar.set_postfix_str(f\" -- {g1}, {g2}\")\n",
    "                \n",
    "        df_temp = model_df[(model_df[\"@Genre\"] == g1) | (model_df[\"@Genre\"] == g2)].reset_index(drop=True)\n",
    "        mean_acc = _train_test(df_temp, model_name, ws, (g1, g2), \"@Genre\", pbar, **kwargs)\n",
    "\n",
    "        accuracy = np.array(mean_acc).mean()\n",
    "        accs.append({\"Genre\": (g1, g2), \"Accuracy\": accuracy})\n",
    "\n",
    "\n",
    "def one_v_all(model_df: pd.DataFrame, model_name: str, accs: List, ws: Dict, genre_list: List, pbar: Optional = None, **kwargs):\n",
    "    for genre in genre_list:\n",
    "        if pbar is not None:\n",
    "            pbar.set_postfix_str(f\" -- {genre}\")\n",
    "        \n",
    "        gtemp = model_df[model_df[\"@Genre\"] == genre].copy().reset_index(drop=True)\n",
    "        not_gtemp = model_df[model_df[\"@Genre\"] != genre].copy().reset_index(drop=True)\n",
    "        \n",
    "        sample_idx = random.sample(range(0, len(not_gtemp)), k=len(gtemp))\n",
    "        \n",
    "        not_gtemp = not_gtemp.iloc[sample_idx].reset_index(drop=True)\n",
    "        not_gtemp[\"@Genre\"] = f\"not {genre}\"\n",
    "        \n",
    "        df_temp = pd.concat([gtemp, not_gtemp])\n",
    "        mean_acc = _train_test(df_temp, model_name, ws, genre, \"@Genre\", pbar, **kwargs)\n",
    "\n",
    "        accuracy = np.array(mean_acc).mean()\n",
    "        accs.append({\"Genre\": genre, \"Accuracy\": accuracy})\n",
    "\n",
    "\n",
    "def _train_test(temp: pd.DataFrame, model_name: str, ws: Dict, wkey: Union[str, tuple], pred_col: str, pbar: Optional = None, **kwargs):\n",
    "    tfi_data = get_df_by_name(temp, model_name, searching=kwargs.get(\"searching\", False))\n",
    "        \n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    y_data = encoder.fit_transform(temp[pred_col])\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    mean_acc = []\n",
    "    for train_index, test_index in kf.split(y_data):\n",
    "\n",
    "        X_train, X_test = tfi_data.iloc[train_index], tfi_data.iloc[test_index]\n",
    "        y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "        preds, clf = predict(X_train, X_test, y_train)\n",
    "\n",
    "        coefs = clf.coef_.ravel()\n",
    "        ws[wkey].append(pd.DataFrame(coefs, index=tfi_data.columns).transpose())\n",
    "\n",
    "        score = np.mean(preds == y_test)\n",
    "        mean_acc.append(score)\n",
    "\n",
    "        if pbar is not None:\n",
    "            pbar.update(1)\n",
    "    \n",
    "    return mean_acc\n",
    "\n",
    "\n",
    "def get_df_by_name(temp: pd.DataFrame, model_name: str, searching: bool = False):\n",
    "    if searching or model_name not in [\"Unigram\", \"Bigram\", \"POS\"]:\n",
    "        return temp.drop(columns=[\"Book #\", \"@Genre\", \"@Outcome\"])\n",
    "    \n",
    "    elif model_name == \"Unigram\":\n",
    "        return tfi_ngram(temp, uni=True)\n",
    "    \n",
    "    elif model_name == \"Bigram\":\n",
    "        return tfi_ngram(temp, bi=True)\n",
    "    \n",
    "    elif model_name == \"POS\":\n",
    "        return temp.drop(columns=[\"Book #\", \"@Genre\", \"@Outcome\", \"CD\", \"$\", \"``\", \"''\"])\n",
    "\n",
    "\n",
    "def get_ens_str(uni: bool = False, roget: bool = False, liwc: bool = False, pos: bool = False, nrc: bool = False, wn: bool = False):\n",
    "    ens_str = []\n",
    "    if uni:\n",
    "        ens_str.append(\"Unigram\")\n",
    "    if roget:\n",
    "        ens_str.append(\"Roget\")\n",
    "    if liwc:\n",
    "        ens_str.append(\"LIWC\")\n",
    "    if pos:\n",
    "        ens_str.append(\"POS\")\n",
    "    if nrc:\n",
    "        ens_str.append(\"NRC\")\n",
    "    if wn:\n",
    "        ens_str.append(\"WordNet\")\n",
    "    return \"_\".join(ens_str)\n",
    "\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def predict(x_train, x_test, y_train):\n",
    "    estimator = svm.LinearSVC()    \n",
    "    estimator.fit(x_train, y_train)\n",
    "    preds = estimator.predict(x_test)\n",
    "    return preds, estimator\n",
    "\n",
    "\n",
    "def create_cmap(cmap, items: List, as_dict: bool = True):\n",
    "    color_list = [to_hex(c) for c in cycler(\"color\", cmap(np.linspace(0, 1, len(items)))).by_key()[\"color\"]]\n",
    "    return dict(zip(items, color_list)) if as_dict else color_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import pickle\n",
    "from roget.roget_thesaurus import RogetThesaurus\n",
    "\n",
    "z = ZipFile(str(PROJ_ROOT.joinpath(\"data\", \"books_by_genre.zip\")))\n",
    "namelist = z.namelist()\n",
    "\n",
    "all_books = {re.search(\"(?<=all_).*(?=_books)\", path)[0]: pickle.load(z.open(path)) for path in namelist}\n",
    "\n",
    "roget_thesaurus = RogetThesaurus(PROJ_ROOT.joinpath(\"roget\", \"roget_thesaurus.csv\"))\n",
    "\n",
    "ACCURACIES = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unigram_data = []\n",
    "bigram_data = []\n",
    "\n",
    "for genre, books in all_books.items():\n",
    "    print(f\"Extracting data from {genre} books...\")\n",
    "    for i, book in enumerate(books):\n",
    "        if book.book_number == \"19513\" or book.book_number == \"19640\" \\\n",
    "                or book.book_number == \"19678\" or book.book_number == \"19782\"\\\n",
    "                or book.book_number == \"19836\":\n",
    "            continue\n",
    "            \n",
    "        _outcome = book.success\n",
    "\n",
    "        first_1k = \"\".join(book.first_1k_sentences)\n",
    "        first_1k = re.sub(\"_\", \"\", first_1k)\n",
    "        first_1k = first_1k.translate(str.maketrans('', '', string.punctuation))\n",
    "        first_1k = re.sub(\"chapter ([ivx]+\\s+|\\w+\\s+?)\", \"\", first_1k, re.IGNORECASE)\n",
    "        \n",
    "        unigram_temp = {\"Book #\": book.book_number, \"@Genre\": genre, \"first_1k\": first_1k, \"@Outcome\": _outcome}\n",
    "        unigram_data.append(unigram_temp)\n",
    "        \n",
    "        bigram_temp = {\"Book #\": book.book_number, \"@Genre\": genre, \"first_1k\": first_1k, \"@Outcome\": _outcome}\n",
    "        bigram_data.append(bigram_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unigram_df = pd.DataFrame(unigram_data)\n",
    "unigram_df.first_1k = unigram_df.first_1k.astype(str)\n",
    "display_df(unigram_df, \"<h4>Unigram Data</h4>\", max_rows=6, formatters={\"first_1k\": lambda s: s[:100] + \"...\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bigram_df = pd.DataFrame(bigram_data)\n",
    "bigram_df.first_1k = bigram_df.first_1k.astype(str)\n",
    "display_df(bigram_df, \"<h4>Bigram Data</h4>\", max_rows=6, formatters={\"first_1k\": lambda s: s[:100] + \"...\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_data = []\n",
    "roget_data = []\n",
    "wordnet_data = [] \n",
    "liwc_data = []\n",
    "swn_data = []\n",
    "nrc_data = []\n",
    "\n",
    "for genre in all_books.keys():\n",
    "    pos_data += pickle.load(open(PROJ_ROOT.joinpath(\"data\", f\"{genre}_pos_data.txt\"), \"rb+\"))\n",
    "    roget_data += pickle.load(open(PROJ_ROOT.joinpath(\"data\", f\"{genre}_roget_data.txt\"), \"rb+\"))\n",
    "    wordnet_data += pickle.load(open(PROJ_ROOT.joinpath(\"data\", f\"{genre}_wordnet_data.txt\"), \"rb+\"))\n",
    "    liwc_data += pickle.load(open(PROJ_ROOT.joinpath(\"data\", f\"{genre}_liwc_data.txt\"), \"rb+\"))\n",
    "    swn_data += pickle.load(open(PROJ_ROOT.joinpath(\"data\", f\"{genre}_swn_data.txt\"), \"rb+\"))\n",
    "    nrc_data += pickle.load(open(PROJ_ROOT.joinpath(\"data\", f\"{genre}_nrc_data.txt\"), \"rb+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_df_scaled, to_display = process_and_scale(pos_data, book_nums=unigram_df[\"Book #\"])\n",
    "display_df(to_display, \"<h4>POS Data</h4>\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roget_df_scaled, to_display = process_and_scale(roget_data, book_nums=unigram_df[\"Book #\"])\n",
    "display_df(to_display, \"<h4>Roget Data</h4>\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordnet_df_scaled, to_display = process_and_scale(wordnet_data, book_nums=unigram_df[\"Book #\"])\n",
    "display_df(to_display, \"<h4>WordNet Data</h4>\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "liwc_df_scaled, to_display = process_and_scale(liwc_data, book_nums=unigram_df[\"Book #\"])\n",
    "display_df(to_display, \"<h4>LIWC Data</h4>\", 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "swn_df_scaled, to_display = process_and_scale(swn_data, book_nums=unigram_df[\"Book #\"])\n",
    "display_df(to_display, \"<h4>SentiWordNet Data</h4>\", 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nrc_df_scaled, to_display = process_and_scale(nrc_data, book_nums=unigram_df[\"Book #\"])\n",
    "display_df(nrc_df_scaled, \"<h4>NRC Sentiment Data</h4>\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Ensemble Method Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def ensemble(uni: bool = False, roget: bool = False, liwc: bool = False, pos: bool = False, nrc: bool = False, wn: bool = False):\n",
    "    ens_acc = []\n",
    "    ens_str = get_ens_str(uni, roget, liwc, pos, nrc, wn)\n",
    "    \n",
    "    for genre in NEW_GENRES:\n",
    "        # print(genre)\n",
    "        encoder = preprocessing.LabelEncoder()\n",
    "        models = []\n",
    "        \n",
    "        if uni:\n",
    "            unigram_df_temp = unigram_df[unigram_df[\"@Genre\"] == genre]\n",
    "            tfi_unigram_data = tfi_ngram(unigram_df_temp, uni=uni)\n",
    "            y_data_unigram = encoder.fit_transform(unigram_df_temp[\"@Outcome\"])\n",
    "            models.append((tfi_unigram_data, y_data_unigram))\n",
    "        if roget:\n",
    "            roget_df_temp = roget_df_scaled[roget_df_scaled[\"@Genre\"] == genre]\n",
    "            tfi_roget_data = roget_df_temp.drop(columns=[\"Book #\", \"@Genre\", \"@Outcome\"])\n",
    "            y_data_roget = encoder.fit_transform(roget_df_temp[\"@Outcome\"])\n",
    "            models.append((tfi_roget_data, y_data_roget))\n",
    "        if liwc:\n",
    "            liwc_df_temp = liwc_df_scaled[liwc_df_scaled[\"@Genre\"] == genre]\n",
    "            tfi_liwc_data = liwc_df_temp.drop(columns=[\"Book #\", \"@Genre\", \"@Outcome\"])\n",
    "            y_data_liwc = encoder.fit_transform(liwc_df_temp[\"@Outcome\"])\n",
    "            models.append((tfi_liwc_data, y_data_liwc))\n",
    "        if pos:\n",
    "            pos_df_temp = pos_df_scaled[pos_df_scaled[\"@Genre\"] == genre]\n",
    "            tfi_pos_data = pos_df_temp.drop(columns=[\"Book #\", \"@Genre\", \"@Outcome\", \"CD\", \"$\", \"``\", \"''\"])\n",
    "            y_data_pos = encoder.fit_transform(pos_df_temp[\"@Outcome\"])\n",
    "            models.append((tfi_pos_data, y_data_pos))\n",
    "        if nrc:\n",
    "            nrc_df_temp = nrc_df_scaled[nrc_df_scaled[\"@Genre\"] == genre]\n",
    "            tfi_nrc_data = nrc_df_temp.drop(columns=[\"Book #\", \"@Genre\", \"@Outcome\"])\n",
    "            y_data_nrc = encoder.fit_transform(nrc_df_temp[\"@Outcome\"])\n",
    "            models.append((tfi_nrc_data, y_data_nrc))\n",
    "        if wn:\n",
    "            wordnet_df_temp = wordnet_df_scaled[wordnet_df_scaled[\"@Genre\"] == genre]\n",
    "            tfi_wordnet_data = wordnet_df_temp.drop(columns=[\"Book #\", \"@Genre\", \"@Outcome\"])\n",
    "            y_data_wn = encoder.fit_transform(wordnet_df_temp[\"@Outcome\"])\n",
    "            models.append((tfi_wordnet_data, y_data_wn))\n",
    "            \n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        mean_acc = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(models[0][1]):\n",
    "            X_trains = []\n",
    "            X_tests = []\n",
    "            y_trains = []\n",
    "            y_tests = []\n",
    "            \n",
    "            for x, y in models:\n",
    "                X_trains.append(x.iloc[train_index])\n",
    "                X_tests.append(x.iloc[test_index])\n",
    "                y_trains.append(y[train_index])\n",
    "                y_tests.append(y[test_index])\n",
    "            \n",
    "            preds = []\n",
    "            probs = []\n",
    "            for x_train, x_test, y_train, y_test in zip(X_trains, X_tests, y_trains, y_tests):\n",
    "                \n",
    "                estimator = svm.LinearSVC()\n",
    "                estimator.fit(x_train, y_train)\n",
    "                preds.append(estimator.predict(x_test))\n",
    "            \n",
    "                if len(models) < 3:\n",
    "                    probs.append(estimator._predict_proba_lr(x_test))\n",
    "                        \n",
    "            ens = []\n",
    "            if len(models) > 2:\n",
    "                for pred in zip(*preds):\n",
    "                    counter = Counter(pred)\n",
    "                    ens.append(max(counter, key=counter.get))\n",
    "            else:\n",
    "                preds1, preds2 = preds[0], preds[1]\n",
    "                probs1, probs2 = probs[0], probs[1]\n",
    "                for pred1, prob1, pred2, prob2 in zip(preds1, probs1, preds2, probs2):\n",
    "                    pred = round(((pred1 * prob1[1]) + (pred2 * prob2[1])) / 2)\n",
    "                    ens.append(pred)\n",
    "            \n",
    "            score = np.mean(ens == y_tests[0])\n",
    "            mean_acc.append(score)\n",
    "        \n",
    "        acc = np.array(mean_acc).mean()\n",
    "        ens_acc.append({\"Genre\": genre, \"Accuracy\": acc})\n",
    "    \n",
    "    ens_acc = pd.DataFrame(ens_acc)\n",
    "    ACCURACIES.update({ens_str: ens_acc})\n",
    "    display_df(ens_acc, f\"<h4>{ens_str} Accuracy by Genre</h4>\")\n",
    "    return ens_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unigram_acc, uni_weights = predict_success(unigram_df, \"Unigram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bigram_acc, bigram_weights = predict_success(bigram_df, \"Bigram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_acc, pos_weights = predict_success(pos_df_scaled, \"POS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Roget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roget_acc, roget_weights = predict_success(roget_df_scaled, \"Roget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordnet_acc, wordnet_weights = predict_success(wordnet_df_scaled, \"WordNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "liwc_acc, liwc_weights = predict_success(liwc_df_scaled, \"LIWC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "swn_acc, swn_weights = predict_success(swn_df_scaled, \"SentiWordNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### NRC Sentiment Emotion Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nrc_acc, nrc_weights = predict_success(nrc_df_scaled, \"NRC Sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Context Free Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: DO THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Unigram Roget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uni_roget_acc = ensemble(uni=True, roget=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Unigram Roget WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uni_roget_wn_ens_acc = ensemble(uni=True, roget=True, wn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Unigram Roget LIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uni_roget_liwc_ens_acc = ensemble(uni=True, roget=True, liwc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigram Roget LIWC Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uni_roget_liwc_nrc_ens_acc = ensemble(uni=True, roget=True, liwc=True, nrc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Unigram POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uni_pos_acc = ensemble(uni=True, pos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Unigram POS Roget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uni_pos_roget_acc = ensemble(uni=True, pos=True, roget=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigram POS Roget LIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uni_pos_roget_liwc_acc = ensemble(uni=True, pos=True, roget=True, liwc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Unigram POS Roget LIWC Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uni_pos_roget_liwc_nrc_acc = ensemble(uni=True, pos=True, roget=True, liwc=True, nrc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Roget LIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "roget_liwc_acc = ensemble(roget=True, liwc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Roget Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "roget_nrc_acc = ensemble(roget=True, nrc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Roget LIWC Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "roget_liwc_nrc_acc = ensemble(roget=True, liwc=True, nrc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### LIWC Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "liwc_nrc_acc = ensemble(liwc=True, nrc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_df_for_reduction(model_name: str, g: Optional[str] = None, g2: Optional[str] = None):\n",
    "    if g is None:\n",
    "        if model_name == \"Unigram\":\n",
    "            out_col = unigram_df[[\"Book #\", \"@Genre\", \"@Outcome\"]].copy().reset_index(drop=True)\n",
    "            data = tfi_ngram(unigram_df, uni=True)\n",
    "            data.insert(0, \"@Genre\", out_col[\"@Genre\"])\n",
    "            data.insert(0, \"Book #\", out_col[\"Book #\"])\n",
    "            data[\"@Outcome\"] = out_col[\"@Outcome\"]\n",
    "            return data\n",
    "        elif model_name == \"Bigram\":\n",
    "            out_col = bigram_df[[\"Book #\", \"@Genre\", \"@Outcome\"]].copy().reset_index(drop=True)\n",
    "            data = tfi_ngram(bigram_df[bigram_df[\"@Genre\"] == g], bi=True)\n",
    "            data.insert(0, \"@Genre\", out_col[\"@Genre\"])\n",
    "            data.insert(0, \"Book #\", out_col[\"Book #\"])\n",
    "            data[\"@Outcome\"] = out_col[\"@Outcome\"]\n",
    "            return data\n",
    "        else:\n",
    "            return globals()[f\"{model_name.lower()}_df_scaled\"].copy()\n",
    "    \n",
    "    if g2 is None:\n",
    "        if model_name == \"Unigram\":\n",
    "            out_col = unigram_df[unigram_df[\"@Genre\"] == g][[\"Book #\", \"@Outcome\"]].copy().reset_index(drop=True)\n",
    "            data = tfi_ngram(unigram_df[unigram_df[\"@Genre\"] == g], uni=True)\n",
    "            data.insert(0, \"@Genre\", g)\n",
    "            data.insert(0, \"Book #\", out_col[\"Book #\"])\n",
    "            data[\"@Outcome\"] = out_col[\"@Outcome\"]\n",
    "            return data\n",
    "        elif model_name == \"Bigram\":\n",
    "            out_col = bigram_df[bigram_df[\"@Genre\"] == g][[\"Book #\", \"@Outcome\"]].copy().reset_index(drop=True)\n",
    "            data = tfi_ngram(bigram_df[bigram_df[\"@Genre\"] == g], bi=True)\n",
    "            data.insert(0, \"@Genre\", g)\n",
    "            data.insert(0, \"Book #\", out_col[\"Book #\"])\n",
    "            data[\"@Outcome\"] = out_col[\"@Outcome\"]\n",
    "            return data\n",
    "        else:\n",
    "            return globals()[f\"{model_name.lower()}_df_scaled\"][globals()[f\"{model_name.lower()}_df_scaled\"][\"@Genre\"] == g].copy()\n",
    "    \n",
    "    else:\n",
    "        if model_name == \"Unigram\":\n",
    "            out_col = unigram_df[(unigram_df[\"@Genre\"] == g) | (unigram_df[\"@Genre\"] == g2)][[\"Book #\", \"@Genre\", \"@Outcome\"]].copy().reset_index(drop=True)\n",
    "            data = tfi_ngram(unigram_df[(unigram_df[\"@Genre\"] == g) | (unigram_df[\"@Genre\"] == g2)], uni=True)\n",
    "            data.insert(0, \"@Genre\", out_col[\"@Genre\"])\n",
    "            data.insert(0, \"Book #\", out_col[\"Book #\"])\n",
    "            data[\"@Outcome\"] = out_col[\"@Outcome\"]\n",
    "            return data\n",
    "        elif model_name == \"Bigram\":\n",
    "            out_col = bigram_df[(bigram_df[\"@Genre\"] == g) | (bigram_df[\"@Genre\"] == g2)][[\"Book #\", \"@Genre\", \"@Outcome\"]].copy().reset_index(drop=True)\n",
    "            data = tfi_ngram(bigram_df[(bigram_df[\"@Genre\"] == g) | (bigram_df[\"@Genre\"] == g2)], bi=True)\n",
    "            data.insert(0, \"@Genre\", out_col[\"@Genre\"])\n",
    "            data.insert(0, \"Book #\", out_col[\"Book #\"])\n",
    "            data[\"@Outcome\"] = out_col[\"@Outcome\"]\n",
    "            return data\n",
    "        else:\n",
    "            scaled_df = globals()[f\"{model_name.lower()}_df_scaled\"]\n",
    "            return scaled_df[(scaled_df[\"@Genre\"] == g) | (scaled_df[\"@Genre\"] == g2)].copy()        \n",
    "\n",
    "\n",
    "def reduce_features(model_weights: Dict, model_name: str, model_df: Optional[pd.DataFrame] = None, max_steps: int = 10,\n",
    "                    genre_list: List = NEW_GENRES, g_predict: Optional[str] = None, og_acc: Optional[pd.DataFrame] = None):\n",
    "    \n",
    "    header = f\"<h4>Performing exhaustive parameter search for feature reduction on {model_name}\"\n",
    "    header += f\"for {g_predict} Genre Prediction</h4>\" if g_predict is not None else \"\"\n",
    "    display(HTML(f\"<h4>Performing exhaustive parameter search for feature reduction on {model_name}</h4>\"))\n",
    "    \n",
    "    og_copy = og_acc.copy()\n",
    "    if \"Average\" in list(og_copy.iloc[:, 0]):\n",
    "        og_copy = og_copy[og_copy[og_copy.columns[0]] != \"Average\"]\n",
    "        \n",
    "    og_copy.insert(1, \"Step\", -0.25)\n",
    "    n_feats = [len(model_weights[k]) for k, v in model_weights.items()]\n",
    "    og_copy[\"Num Features\"] = n_feats\n",
    "    \n",
    "    exhaustive = og_copy.to_dict(\"records\")\n",
    "    reduced_features = {genre: model_weights[genre].copy() for genre in genre_list}\n",
    "    \n",
    "    steps = np.arange(0, max_steps + 0.25, 0.25)\n",
    "    with tqdm(total=len(steps) * len(genre_list)) as pbar:\n",
    "        for genre in genre_list:\n",
    "            pbar.set_postfix_str(f\" -- {genre}\")\n",
    "            best_acc = og_acc[\"Accuracy\"].mean()\n",
    "            \n",
    "            if model_df is None:\n",
    "                if g_predict == \"one_v_one\":\n",
    "                    scaled_df = get_df_for_reduction(model_name, genre[0], genre[1])\n",
    "                elif g_predict == \"one_v_all\":\n",
    "                    scaled_df = get_df_for_reduction(model_name)\n",
    "                else:\n",
    "                    scaled_df = get_df_for_reduction(model_name, genre)\n",
    "            else:\n",
    "                if g_predict == \"one_v_one\":\n",
    "                    scaled_df = model_df[(model_df[\"@Genre\"] == genre[0]) | (model_df[\"@Genre\"] == genre[1])].copy()\n",
    "                elif g_predict == \"one_v_all\":\n",
    "                    scaled_df = model_df.copy()\n",
    "                else:\n",
    "                    scaled_df = model_df[model_df[\"@Genre\"] == genre].copy()\n",
    "            \n",
    "            for i, step in enumerate(steps):\n",
    "                avg_weight = model_weights[genre][\"Weight\"].mean()\n",
    "                std_dev = model_weights[genre][\"Weight\"].std()\n",
    "                threshold = avg_weight + (step * std_dev)\n",
    "                param_results = model_weights[genre][model_weights[genre][\"Weight\"].abs() >= threshold]\n",
    "\n",
    "                if len(param_results) < 5:\n",
    "                    print(f\"{genre} exhausted at {step} deviations above the mean\")\n",
    "                    pbar.update(len(steps) - i)\n",
    "                    break\n",
    "                \n",
    "                elif step == max_steps:\n",
    "                    print(f\"{genre} did not exhaust, len(results) = {len(param_results)}\")\n",
    "\n",
    "                elif len(param_results) == len(model_weights[genre][\"Weight\"]):\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                col_filter = set(param_results[\"Feature\"])\n",
    "                cols = [\"Book #\", \"@Genre\"] + list(col_filter) + [\"@Outcome\"]\n",
    "                param_results_df = scaled_df[cols]\n",
    "\n",
    "                if g_predict is not None:\n",
    "                    param_acc, param_weights = predict_genre(param_results_df, model_name, how=g_predict, searching=True,\n",
    "                                                             genre_list=[genre], disp_acc=False, disp_weights=False, show_pbar=False)\n",
    "                    if g_predict == \"one_v_one\":\n",
    "                        step_acc = param_acc.loc[param_acc[\"Genre\"] == (genre[0], genre[1]), \"Accuracy\"].values[0]\n",
    "                    else:\n",
    "                        step_acc = param_acc.loc[param_acc[\"Genre\"] != \"Average\", \"Accuracy\"].values[0]\n",
    "                else:\n",
    "                    param_acc, param_weights = predict_success(param_results_df, model_name, searching=True,\n",
    "                                                               genre_list=[genre], disp_acc=False, disp_weights=False, show_pbar=False)\n",
    "                    step_acc = param_acc.loc[param_acc[\"Genre\"] != \"Average\", \"Accuracy\"].values[0]\n",
    "                    \n",
    "                if step_acc > best_acc:\n",
    "                    best_acc = step_acc\n",
    "                    reduced_features[genre] = param_weights[genre].copy()\n",
    "\n",
    "                exhaustive.append({\"Genre\": genre, \"Step\": step, \"Accuracy\": step_acc, \"Num Features\": len(param_weights[genre])})\n",
    "                pbar.update(1)\n",
    "\n",
    "    exhaustive_df = pd.DataFrame(exhaustive)\n",
    "    return exhaustive_df, reduced_features\n",
    "\n",
    "\n",
    "def plot_exhausted(exh_df_: pd.DataFrame, max_steps: int = 10, markersize: int = 10, \n",
    "                   genre_list: List = NEW_GENRES, colors: Optional[Dict] = None, markers: bool = True):\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(30, 15))\n",
    "\n",
    "    exh_df = exh_df_.copy()\n",
    "    tuned_params = []\n",
    "    tuned_params_dict = {}\n",
    "    markers = [\"o\", \"P\", \"s\", \"D\", \"p\", \"v\", \"H\", \"*\"]\n",
    "    \n",
    "    i = 0\n",
    "    while len(genre_list) > len(markers):\n",
    "        markers.append(markers[i])\n",
    "        i += 1\n",
    "        if i >= len(markers):\n",
    "            i = 0\n",
    "    \n",
    "    if markers:\n",
    "        for genre, m in zip(genre_list, markers):\n",
    "            best = exh_df[(exh_df[\"Genre\"] == genre)][\"Accuracy\"].max()\n",
    "            best_param = exh_df.loc[(exh_df[\"Genre\"] == genre) & (exh_df[\"Accuracy\"] == best), \"Step\"].values[0]\n",
    "            n_features = exh_df.loc[(exh_df[\"Genre\"] == genre) & (exh_df[\"Accuracy\"] == best), \"Num Features\"].values[0]\n",
    "            tuned_params.append({\"Genre\": genre, \"Deviations\": best_param, \"Accuracy\": best, \"Num Features\": n_features})\n",
    "            tuned_params_dict[genre] = {\"Deviations\": best_param, \"Accuracy\": best}\n",
    "            if colors is None:\n",
    "                exh_df[exh_df[\"Genre\"] == genre][[\"Step\", \"Accuracy\"]].plot(x=\"Step\", ax=axes, rot=0, marker=m if len(genre_list) <= len(NEW_GENRES) else \"\",\n",
    "                                                                            markersize=markersize, markeredgewidth=2, fillstyle=\"none\", linewidth=2)\n",
    "            else:\n",
    "                exh_df[exh_df[\"Genre\"] == genre][[\"Step\", \"Accuracy\"]].plot(x=\"Step\", ax=axes, rot=0, color=colors[genre],\n",
    "                                                                            marker=m if len(genre_list) <= len(NEW_GENRES) else \"\",\n",
    "                                                                            markersize=markersize, markeredgewidth=2, fillstyle=\"none\", linewidth=2)\n",
    "    else:\n",
    "        for genre in genre_list:\n",
    "            best = exh_df[(exh_df[\"Genre\"] == genre)][\"Accuracy\"].max()\n",
    "            best_param = exh_df.loc[(exh_df[\"Genre\"] == genre) & (exh_df[\"Accuracy\"] == best), \"Step\"].values[0]\n",
    "            n_features = exh_df.loc[(exh_df[\"Genre\"] == genre) & (exh_df[\"Accuracy\"] == best), \"Num Features\"].values[0]\n",
    "            tuned_params.append({\"Genre\": genre, \"Deviations\": best_param, \"Accuracy\": best, \"Num Features\": n_features})\n",
    "            tuned_params_dict[genre] = {\"Deviations\": best_param, \"Accuracy\": best}\n",
    "            if colors is None:\n",
    "                exh_df[exh_df[\"Genre\"] == genre][[\"Step\", \"Accuracy\"]].plot(x=\"Step\", ax=axes, rot=0, linewidth=2)\n",
    "            else:\n",
    "                exh_df[exh_df[\"Genre\"] == genre][[\"Step\", \"Accuracy\"]].plot(x=\"Step\", ax=axes, rot=0, color=colors[genre], linewidth=2)\n",
    "    \n",
    "    tuned_params_df = pd.DataFrame(tuned_params)\n",
    "    display_df(tuned_params_df.copy().append({\"Genre\": \"Average\",\n",
    "                                              \"Deviations\": tuned_params_df[\"Deviations\"].mean(),\n",
    "                                              \"Accuracy\": tuned_params_df[\"Accuracy\"].mean(),\n",
    "                                              \"Num Features\": tuned_params_df[\"Num Features\"].mean()}, ignore_index=True))\n",
    "    \n",
    "    if max_steps > 15:\n",
    "        minor_step = 1 if max_steps > 35 else 0.5\n",
    "        xmajor = floor(max_steps / 5) if max_steps > 35 else max_steps\n",
    "        xminor = xmajor * 4\n",
    "    elif exh_df[\"Step\"].max() <= 6:\n",
    "        xmajor = max_steps * 4\n",
    "        xminor = xmajor * 5\n",
    "        minor_step = 0.05\n",
    "    else:\n",
    "        xmajor = max_steps * 2\n",
    "        xminor = xmajor * 2\n",
    "        minor_step = 0.25\n",
    "    \n",
    "    setup_axis(axes, xmin=-0.25, xmax=max_steps, xmajor=xmajor, xminor=xminor,\n",
    "               xlabel=\"Deviations above the Mean\", ylabel=\"Accuracy\",\n",
    "               left=exh_df[\"Step\"].min() - minor_step, right=exh_df[\"Step\"].max() + minor_step,\n",
    "               bottom=exh_df[\"Accuracy\"].min() - 0.025, top=tuned_params_df[\"Accuracy\"].max() + 0.025,\n",
    "               grid=\"-\", minor_grid=\":\")\n",
    "    \n",
    "    if genre_list == NEW_GENRES:\n",
    "        axes.legend(genre_list, bbox_to_anchor=(0.9915, 1.07), fontsize=19, ncol=len(genre_list))\n",
    "    else:\n",
    "        axes.legend(genre_list, bbox_to_anchor=(1.005, 1), loc=\"upper left\", fontsize=19)\n",
    "\n",
    "    plt.margins(x=0.01, y=0.05)    \n",
    "    plt.show()\n",
    "    return tuned_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uni_exh, uni_rw = reduce_features(uni_weights, \"Unigram\", max_steps=35, og_acc=unigram_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uni_reduced_acc = plot_exhausted(uni_exh, max_steps=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bi_exh, bi_weights_reduced = reduce_features(bigram_weights, \"Bigram\", max_steps=75, og_acc=bigram_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bi_reduced_acc = plot_exhausted(bi_exh, max_steps=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_exh, pos_weights_reduced = reduce_features(pos_weights, \"POS\", og_acc=pos_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_reduced_acc = plot_exhausted(pos_exh, markersize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roget_exh, roget_rw = reduce_features(roget_weights, \"Roget\", og_acc=roget_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roget_reduced_acc = plot_exhausted(roget_exh, markersize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wn_exh, wn_rw = reduce_features(wordnet_weights, \"WordNet\", max_steps=15, og_acc=wordnet_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in NEW_GENRES:\n",
    "    display_df(wn_rw[genre], genre, max_rows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wn_reduced_acc = plot_exhausted(wn_exh, max_steps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "liwc_exh, liwc_weights_reduced = reduce_features(liwc_weights, \"LIWC\", og_acc=liwc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "liwc_reduced_acc = plot_exhausted(liwc_exh, markersize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping WordNet to Roget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roget_invert = []\n",
    "\n",
    "display(HTML(\"<b>Converting Roget DataFrame to be by Word...</b>\"))\n",
    "with tqdm(total=len(roget_thesaurus.roget_df)) as pbar:\n",
    "    for idx, row in roget_thesaurus.roget_df.iterrows():\n",
    "        for word in set(row[\"Words\"]):\n",
    "            roget_invert.append({\"Word\": word, \"Category\": row[\"Category\"], \"Level3\": row[\"Level3\"], \"Level2\": row[\"Level2\"],\n",
    "                                 \"Level1\": row[\"Level1\"], \"Section\": row[\"Section\"], \"Class\": row[\"Class\"]})\n",
    "        pbar.update(1)\n",
    "\n",
    "roget_thesaurus_df = pd.DataFrame(roget_invert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wn_df = pd.DataFrame(wordnet_data).fillna(0).rename(columns={\"_genre\": \"@Genre\", \"_outcome\": \"@Outcome\"})\n",
    "wn_df.insert(0, \"Book #\", unigram_df[\"Book #\"].reset_index(drop=True))\n",
    "wnrf_set = {genre: wn_df[wn_df[\"@Genre\"] == genre][[\"Book #\", \"@Genre\"] + [w for w in wn_rw[genre][\"Feature\"]] + [\"@Outcome\"]] for genre in NEW_GENRES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumsAndOutcomes = {genre: wn_df[wn_df[\"@Genre\"] == genre][[\"Book #\", \"@Genre\", \"@Outcome\"]].reset_index(drop=True) for genre in NEW_GENRES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def map_to_roget(dfs_to_map: Dict, src_model: str, genre_list: List = NEW_GENRES, to_categories: bool = False, to_sections: bool = False, to_classes: bool = False):\n",
    "    map_from = \"Word\" if to_categories else \"Category\" if to_sections else \"Section\"\n",
    "    map_to = \"Category\" if to_categories else \"Section\" if to_sections else \"Class\"\n",
    "    display(HTML(f\"<h4>Mapping {src_model} to Roget {map_to}...</h4>\"))\n",
    "    \n",
    "    mapped_dict = {genre: {} for genre in genre_list}\n",
    "    bar_length = sum(len(dfs_to_map[genre].columns) - 3 for genre in genre_list)\n",
    "    \n",
    "    with tqdm(total=bar_length) as pbar:\n",
    "        for genre in genre_list:\n",
    "            pbar.set_postfix_str(f\" -- {genre}\")\n",
    "            mapping_cols = dfs_to_map[genre].drop(columns=[\"Book #\", \"@Genre\", \"@Outcome\"]).columns\n",
    "            \n",
    "            for col in mapping_cols:\n",
    "                roget_map = roget_thesaurus_df[roget_thesaurus_df[map_from] == col][map_to]\n",
    "                \n",
    "                if to_sections or to_classes:\n",
    "                    roget_map = roget_map.unique()\n",
    "                \n",
    "                for mapping in roget_map:\n",
    "                    if mapping in mapped_dict[genre].keys():\n",
    "                        mapped_dict[genre][mapping] = pd.concat([mapped_dict[genre][mapping], dfs_to_map[genre][col]], axis=1)\n",
    "                    else:\n",
    "                        mapped_dict[genre][mapping] = dfs_to_map[genre][[col]]\n",
    "                pbar.update(1)\n",
    "    \n",
    "    return mapped_dict\n",
    "\n",
    "\n",
    "def concat_map_to_roget(map_to_roget_dict: Dict, src_model: str, map_to: str, genre_list: List = NEW_GENRES, nums_outcomes: Dict = NumsAndOutcomes):\n",
    "    no_scale = {}\n",
    "    display(HTML(f\"<h4>Concatenating {src_model} to Roget {map_to} -- no scaling...</h4>\"))\n",
    "    with tqdm(total=len(genre_list)) as pbar:\n",
    "        for genre in genre_list:\n",
    "            pbar.set_postfix_str(f\" -- {genre}\")\n",
    "            mapped = pd.concat([pd.DataFrame({k: map_to_roget_dict[genre][k].sum(axis=1).reset_index(drop=True)}) for k in map_to_roget_dict[genre].keys()], axis=1)\n",
    "            mapped.insert(0, \"@Genre\", nums_outcomes[genre][\"@Genre\"])\n",
    "            mapped.insert(0, \"Book #\", nums_outcomes[genre][\"Book #\"])\n",
    "            mapped[\"@Outcome\"] = nums_outcomes[genre][\"@Outcome\"]\n",
    "            no_scale[genre] = mapped\n",
    "            pbar.update(1)\n",
    "\n",
    "    scaled = {}\n",
    "    display(HTML(f\"<h4>Concatenating {src_model} to Roget {map_to} -- scaling by genre...</h4>\"))\n",
    "    with tqdm(total=len(genre_list)) as pbar:\n",
    "        for genre in genre_list:\n",
    "            pbar.set_postfix_str(f\" -- {genre}\")\n",
    "            mapped = pd.concat([pd.DataFrame({k: map_to_roget_dict[genre][k].sum(axis=1).reset_index(drop=True)}) for k in map_to_roget_dict[genre].keys()], axis=1)\n",
    "            mapped.insert(0, \"@Genre\", nums_outcomes[genre][\"@Genre\"])\n",
    "            mapped.insert(0, \"Book #\", nums_outcomes[genre][\"Book #\"])\n",
    "            mapped[\"@Outcome\"] = nums_outcomes[genre][\"@Outcome\"]\n",
    "            scaled[genre], _ = process_and_scale(mapped)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    return no_scale, scaled\n",
    "\n",
    "\n",
    "def test_map_to_roget(no_scale: Dict, scaled_: Dict, src_model: str, map_to: str, genre_list: List = NEW_GENRES, g_predict: Optional[str] = None):\n",
    "    display(HTML(f\"<h4>Testing {src_model} to Roget {map_to} -- All Genres Scaled</h4>\"))\n",
    "    full_map_to_roget = pd.concat(list(no_scale.values())).fillna(0)\n",
    "    full_map_to_roget_scaled, _ = process_and_scale(full_map_to_roget)\n",
    "\n",
    "    if g_predict is not None:\n",
    "        scaled = pd.concat(list(scaled_.values())).fillna(0)\n",
    "        full_map_to_roget_acc, full_map_to_roget_weights = predict_genre(full_map_to_roget_scaled, f\"{src_model} to Roget {map_to}\",\n",
    "                                                                         how=g_predict, genre_list=genre_list, disp_acc=False,\n",
    "                                                                         disp_weights=False, show_pbar=False)\n",
    "    else:\n",
    "        full_map_to_roget_acc, full_map_to_roget_weights = predict_success(full_map_to_roget_scaled, f\"{src_model} to Roget {map_to}\",\n",
    "                                                                           genre_list=genre_list, disp_acc=False,\n",
    "                                                                           disp_weights=False, show_pbar=False)\n",
    "    \n",
    "    full_map_to_roget_acc = full_map_to_roget_acc[full_map_to_roget_acc[\"Genre\"] != \"Average\"]\n",
    "    full_map_to_roget_acc = full_map_to_roget_acc.append({\"Genre\": \"Average\", \"Accuracy\": full_map_to_roget_acc[\"Accuracy\"].mean()}, ignore_index=True)\n",
    "    display_df(full_map_to_roget_acc)\n",
    "\n",
    "    display(HTML(f\"<h4>Testing {src_model} to Roget {map_to} -- Scaled By Genre</h4>\"))\n",
    "    map_to_roget_results = []\n",
    "    map_to_roget_weights = {}\n",
    "    \n",
    "    for genre in genre_list:\n",
    "        if g_predict is not None:\n",
    "            acc, weights = predict_genre(scaled, f\"{src_model} to Roget {map_to}\", how=g_predict, searching=True,\n",
    "                                         genre_list=[genre], disp_acc=False, disp_weights=False, show_pbar=False)\n",
    "        else:\n",
    "            acc, weights = predict_success(scaled_[genre], f\"{src_model} to Roget {map_to}\", searching=True,\n",
    "                                           genre_list=[genre], disp_acc=False, disp_weights=False, show_pbar=False)\n",
    "\n",
    "        acc = acc[acc[\"Genre\"] != \"Average\"]\n",
    "        map_to_roget_results.append(acc)\n",
    "        map_to_roget_weights.update(weights)\n",
    "\n",
    "    map_to_roget_acc = pd.concat(map_to_roget_results)\n",
    "    map_to_roget_acc = map_to_roget_acc.append({\"Genre\": \"Average\", \"Accuracy\": map_to_roget_acc[\"Accuracy\"].mean()}, ignore_index=True)\n",
    "    display_df(map_to_roget_acc)\n",
    "    \n",
    "    return full_map_to_roget_acc, full_map_to_roget_weights, map_to_roget_acc, map_to_roget_weights\n",
    "\n",
    "\n",
    "# def test_map_to_roget(no_scale: Dict, scaled: Dict, src_model: str, map_to: str, genre_list: List = NEW_GENRES, g_predict: Optional[str] = None):\n",
    "#     full_map_to_roget = pd.concat(list(no_scale.values())).fillna(0)\n",
    "#     full_map_to_roget_scaled, _ = process_and_scale(full_map_to_roget)\n",
    "\n",
    "#     if g_predict is not None:\n",
    "#         full_map_to_roget_acc, full_map_to_roget_weights = predict_genre(full_map_to_roget_scaled, f\"{src_model} to Roget {map_to}\",\n",
    "#                                                                          how=g_predict, genre_list=genre_list, add_to_acc=False,\n",
    "#                                                                          disp_acc=False, disp_weights=False, show_pbar=False)\n",
    "#         map_to_roget = pd.concat(list(scaled.values())).fillna(0)\n",
    "#         map_to_roget_acc, map_to_roget_weights = predict_genre(map_to_roget, f\"{src_model} to Roget {map_to}\",\n",
    "#                                                                how=g_predict, genre_list=genre_list, add_to_acc=False,\n",
    "#                                                                disp_acc=False, disp_weights=False, show_pbar=False)\n",
    "\n",
    "#     else:\n",
    "#         full_map_to_roget_acc, full_map_to_roget_weights = predict_success(full_map_to_roget_scaled, f\"{src_model} to Roget {map_to}\",\n",
    "#                                                                            genre_list=genre_list, disp_acc=False,\n",
    "#                                                                            disp_weights=False, show_pbar=False)\n",
    "#         map_to_roget_results = []\n",
    "#         map_to_roget_weights = {}\n",
    "\n",
    "#         for genre in genre_list:\n",
    "#             acc, weights = predict_success(scaled[genre], f\"{src_model} to Roget {map_to}\", searching=True, add_to_acc=False,\n",
    "#                                            genre_list=[genre], disp_acc=False, disp_weights=False, show_pbar=False)\n",
    "\n",
    "#             map_to_roget_results.append(acc)\n",
    "#             map_to_roget_weights.update(weights)\n",
    "\n",
    "#         map_to_roget_acc = pd.concat(map_to_roget_results)\n",
    "    \n",
    "#     display_df(full_map_to_roget_acc, f\"<h4>{src_model} to Roget {map_to} -- All Genres Scaled</h4>\")\n",
    "#     display_df(map_to_roget_acc, f\"<h4>{src_model} to Roget {map_to} -- Scaled By Genre</h4>\")\n",
    "    \n",
    "#     return full_map_to_roget_acc, full_map_to_roget_weights, map_to_roget_acc, map_to_roget_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnrf_to_rocat = map_to_roget(wnrf_set, src_model=\"WordNet\", to_categories=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wnrf_to_rocat_no_scale, wnrf_to_rocat_scaled = concat_map_to_roget(wnrf_to_rocat, src_model=\"WordNet\", map_to=\"Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = test_map_to_roget(wnrf_to_rocat_no_scale, wnrf_to_rocat_scaled, src_model=\"WordNet\", map_to=\"Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wnrf_to_rosect = map_to_roget(wnrf_to_rocat_no_scale, src_model=\"WordNet\", to_sections=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wnrf_to_rosect_no_scale, wnrf_to_rosect_scaled = concat_map_to_roget(wnrf_to_rosect, src_model=\"WordNet\", map_to=\"Section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_wnrf_to_rosect_acc, full_wnrf_to_rosect_weights, wnrf_to_rosect_acc, wnrf_to_rosect_weights = test_map_to_roget(wnrf_to_rosect_no_scale, wnrf_to_rosect_scaled, src_model=\"WordNet\", map_to=\"Section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnrf_to_rosect_df = pd.concat(list(wnrf_to_rosect_no_scale.values())).fillna(0)\n",
    "wnrf_to_rosect_df_scaled, _ = process_and_scale(wnrf_to_rosect_df)\n",
    "wnrf_to_rosect_exh, wnrf_to_rosect_rw = reduce_features(full_wnrf_to_rosect_weights, \"WordNet to Roget Section\",\n",
    "                                                        model_df=wnrf_to_rosect_df_scaled, og_acc=full_wnrf_to_rosect_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wnrf_to_rosect_reduced_acc = plot_exhausted(wnrf_to_rosect_exh, markersize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnrf_to_roget_class = map_to_roget(wnrf_to_rosect_no_scale, src_model=\"WordNet\", to_classes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnrf_to_roget_class_no_scale, wnrf_to_roget_class_scaled = concat_map_to_roget(wnrf_to_roget_class, src_model=\"WordNet\", map_to=\"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = test_map_to_roget(wnrf_to_roget_class_no_scale, wnrf_to_roget_class_scaled, src_model=\"WordNet\", map_to=\"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_themes_by_genre(no_scale: Dict, sect_weights: Dict, genre_list: List = NEW_GENRES):\n",
    "    themes_by_genre = []\n",
    "    full_no_scale = pd.concat(list(no_scale.values())).fillna(0)\n",
    "    bar_length = len(full_no_scale.drop(columns=[\"Book #\", \"@Genre\", \"@Outcome\"]).columns) * len(genre_list)\n",
    "    themes = list(full_no_scale.drop(columns=[\"Book #\", \"@Genre\", \"@Outcome\"]).columns)\n",
    "    themes.sort()\n",
    "\n",
    "    display(HTML(\"<h4>Getting themes by genre...</h4>\"))\n",
    "    with tqdm(total=bar_length) as pbar:\n",
    "        for genre in genre_list:\n",
    "            pbar.set_postfix_str(f\" -- {genre}\")\n",
    "            for theme in themes:\n",
    "                try:\n",
    "                    theme_weight = sect_weights[genre].set_index(\"Feature\").loc[theme, \"Weight\"]\n",
    "                except KeyError:\n",
    "                    theme_weight = 0\n",
    "                themes_by_genre.append({\"Genre\": genre, \"Theme\": theme, \"Weight\": theme_weight})\n",
    "                pbar.update(1)\n",
    "\n",
    "    tbg_df = pd.DataFrame(themes_by_genre)\n",
    "    tbg_df.loc[tbg_df[\"Theme\"] == theme, \"Weight\"] = tbg_df.loc[tbg_df[\"Theme\"] == theme, \"Weight\"].abs()\n",
    "    # for theme in themes:\n",
    "    #     tbg_weights_scaled = scale.fit_transform(tbg_df.loc[tbg_df[\"Theme\"] == theme][[\"Weight\"]].abs())\n",
    "    #     tbg_df.loc[tbg_df[\"Theme\"] == theme, \"Weight\"] = tbg_weights_scaled\n",
    "    \n",
    "    return tbg_df, themes\n",
    "\n",
    "\n",
    "def plot_tbg(tbg_df: pd.DataFrame, themes: List, colors: Dict, sort: bool = False, scatter: bool = False):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(30,15))\n",
    "\n",
    "    if sort:\n",
    "        sorted_tbg_df = get_sorted_tbg(tbg_df, colors)\n",
    "        for i in range(len(sorted_tbg_df[\"Theme\"])):\n",
    "            axes.bar(sorted_tbg_df[\"Theme\"][i], sorted_tbg_df[\"percentage\"][i], width=0.5, color=sorted_tbg_df[\"color\"][i],\n",
    "                     bottom=sorted_tbg_df[\"bottoms\"][i], label=sorted_tbg_df[\"Genre\"][i])\n",
    "\n",
    "        plt.xticks(rotation=90)\n",
    "\n",
    "    else:\n",
    "        if scatter:\n",
    "            for genre, color in zip(NEW_GENRES, list(colors.values())):\n",
    "                sizes = tbg_df[tbg_df[\"Genre\"] == genre].sort_values(by=[\"Theme\"])[\"Weight\"]*2**12\n",
    "                tbg_df[tbg_df[\"Genre\"] == genre].sort_values(by=[\"Theme\"]).plot(x=\"Theme\", y=\"Weight\", ax=axes, kind=\"scatter\", s=sizes, rot=90, c=color, alpha=0.9)\n",
    "        else:\n",
    "            tbg_percentage = tbg_df.copy()\n",
    "            for theme in themes:\n",
    "                theme_sum = tbg_percentage.loc[tbg_percentage[\"Theme\"] == theme, \"Weight\"].sum()\n",
    "                tbg_percentage.loc[tbg_percentage[\"Theme\"] == theme, \"Weight\"] /= theme_sum\n",
    "            \n",
    "            margin_bottom = np.zeros(len(tbg_percentage[\"Theme\"].drop_duplicates()))\n",
    "\n",
    "            for genre, color in zip(NEW_GENRES, list(colors.values())):\n",
    "                values = list(tbg_percentage[tbg_percentage[\"Genre\"] == genre].sort_values(by=[\"Theme\"]).loc[:, \"Weight\"])\n",
    "                tbg_percentage[tbg_percentage[\"Genre\"] == genre].sort_values(by=[\"Theme\"]).plot.bar(x=\"Theme\", y=\"Weight\", ax=axes, stacked=True, width=0.5,\n",
    "                                                                                                    bottom=margin_bottom, rot=90, color=color)\n",
    "                margin_bottom += values\n",
    "\n",
    "    if sort:\n",
    "        setup_axis(axes, xmin=None, ymajor=10, ylabel=\"Weight Percentage\")\n",
    "    else:\n",
    "        setup_axis(axes, ymajor=10, x_ticklabels=themes, ylabel=\"Weight Percentage\" if not scatter else \"Weight\",\n",
    "                   bottom=-0.01 if scatter else None, top=1.05 if scatter else None)\n",
    "\n",
    "    if sort:\n",
    "        axes.legend(bbox_to_anchor=(0.9915, 1.07), fontsize=19, ncol=len(NEW_GENRES))\n",
    "        handles, labels = axes.get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        sorted_keys = sorted(by_label)\n",
    "        sorted_vals = [by_label[k] for k in sorted_keys]\n",
    "        by_label = dict(zip(sorted_keys, sorted_vals))\n",
    "        axes.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(0.9915, 1.07), fontsize=19, ncol=len(NEW_GENRES))\n",
    "    elif scatter:\n",
    "        legend = axes.legend(NEW_GENRES, bbox_to_anchor=(0.9915, 1.07), fontsize=19, ncol=len(NEW_GENRES))\n",
    "        for i in range(len(legend.legendHandles)):\n",
    "            legend.legendHandles[i]._sizes = [250]\n",
    "    else:\n",
    "        axes.legend(NEW_GENRES, bbox_to_anchor=(0.9915, 1.07), fontsize=19, ncol=len(NEW_GENRES))\n",
    "        \n",
    "    plt.margins(x=0.025, y=0.05)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_sorted_tbg(tbg_df: pd.DataFrame, colors: Dict):\n",
    "    s_tbg_df = tbg_df.copy()\n",
    "    \n",
    "    s_tbg_df[\"percentage\"] = s_tbg_df[\"Weight\"] / s_tbg_df.groupby(\"Theme\")[\"Weight\"].transform(\"sum\")\n",
    "    s_tbg_df.sort_values(\"percentage\", ascending=False, inplace=True)\n",
    "    \n",
    "    s_tbg_df = s_tbg_df.groupby(\"Theme\").apply(ranker)\n",
    "    s_tbg_df.sort_values([\"Theme\", \"rank\"], ascending=[True, True], inplace=True)\n",
    "    \n",
    "    s_tbg_df[\"color\"] = s_tbg_df.apply(color_assigment, args=(colors,), axis=1)\n",
    "    \n",
    "    s_tbg_df[\"bottoms\"] = s_tbg_df.groupby(\"Theme\")[\"percentage\"].cumsum() - s_tbg_df[\"percentage\"]\n",
    "    s_tbg_df[\"Theme\"] = s_tbg_df[\"Theme\"].astype(str)\n",
    "    \n",
    "    s_tbg_df = s_tbg_df.reset_index(drop=True)\n",
    "    return s_tbg_df\n",
    "\n",
    "\n",
    "def ranker(df: pd.DataFrame):\n",
    "    df[\"rank\"] = np.arange(len(df)) + 1\n",
    "    return df\n",
    "\n",
    "\n",
    "def color_assigment(df: pd.DataFrame, colors: Dict):\n",
    "    return colors[df[\"Genre\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "\n",
    "def get_rosect_freq(scaled: Dict, themes: List, sect_weights: Dict, genre_list: List = NEW_GENRES, g_predict: Optional[str] = None):\n",
    "    map_to_rosect_wvs = {genre: [] for genre in genre_list}\n",
    "    display(HTML(\"<h4>Calculating Roget Section Frequency by Success per Genre</h4>\"))\n",
    "    with tqdm(total=len(genre_list)) as pbar:\n",
    "        for genre in genre_list:\n",
    "            pbar.set_postfix_str(f\" -- {genre}\")\n",
    "\n",
    "            for theme in themes:\n",
    "                try:\n",
    "                    if g_predict == \"one_v_one\":\n",
    "                        theme_avg_freq1 = scaled[genre].loc[scaled[genre][\"@Genre\"] == genre[0], theme].mean()\n",
    "                        theme_avg_freq2 = scaled[genre].loc[scaled[genre][\"@Genre\"] == genre[1], theme].mean()\n",
    "                    elif g_predict == \"one_v_all\":\n",
    "                        ova = pd.concat(list(scaled.values())).fillna(0)\n",
    "                        theme_avg_freq1 = ova.loc[ova[\"@Genre\"] == genre, theme].mean()\n",
    "                        theme_avg_freq2 = ova.loc[ova[\"@Genre\"] != genre, theme].mean()\n",
    "                    else:\n",
    "                        theme_avg_freq1 = scaled[genre].loc[scaled[genre][\"@Outcome\"] == \"SUCCESSFUL\", theme].mean()\n",
    "                        theme_avg_freq2 = scaled[genre].loc[scaled[genre][\"@Outcome\"] == \"FAILURE\", theme].mean()\n",
    "                except KeyError as e:\n",
    "                    scaled[genre][theme] = 0\n",
    "                    if g_predict == \"one_v_one\":\n",
    "                        theme_avg_freq1 = scaled[genre].loc[scaled[genre][\"@Genre\"] == genre[0], theme].mean()\n",
    "                        theme_avg_freq2 = scaled[genre].loc[scaled[genre][\"@Genre\"] == genre[1], theme].mean()\n",
    "                    elif g_predict == \"one_v_all\":\n",
    "                        ova = pd.concat(list(scaled.values())).fillna(0)\n",
    "                        theme_avg_freq1 = ova.loc[ova[\"@Genre\"] == genre, theme].mean()\n",
    "                        theme_avg_freq2 = ova.loc[ova[\"@Genre\"] != genre, theme].mean()\n",
    "                    else:\n",
    "                        theme_avg_freq1 = scaled[genre].loc[scaled[genre][\"@Outcome\"] == \"SUCCESSFUL\", theme].mean()\n",
    "                        theme_avg_freq2 = scaled[genre].loc[scaled[genre][\"@Outcome\"] == \"FAILURE\", theme].mean()\n",
    "\n",
    "                try:\n",
    "                    weight = abs(sect_weights[genre].set_index(\"Feature\").loc[theme, \"Weight\"])\n",
    "                except KeyError:\n",
    "                    weight = 0\n",
    "\n",
    "                freq_diff = theme_avg_freq1 - theme_avg_freq2\n",
    "                map_to_rosect_wvs[genre].append({\"Genre\": genre, \"Theme\": theme, \"Frequency Difference\": freq_diff, \"Weight\": weight})\n",
    "\n",
    "            map_to_rosect_wvs[genre] = pd.DataFrame(map_to_rosect_wvs[genre]).sort_values(by=[\"Theme\"])\n",
    "            map_to_rosect_wvs[genre] = map_to_rosect_wvs[genre][(map_to_rosect_wvs[genre][\"Frequency Difference\"] != 0) | \n",
    "                                                                (map_to_rosect_wvs[genre][\"Weight\"] != 0)].reset_index(drop=True)\n",
    "            pbar.update(1)\n",
    "\n",
    "    for genre in genre_list:\n",
    "        map_to_rosect_wvs_scaled = scale.fit_transform(map_to_rosect_wvs[genre].loc[map_to_rosect_wvs[genre][\"Genre\"] == genre][[\"Weight\"]])\n",
    "        map_to_rosect_wvs[genre].loc[map_to_rosect_wvs[genre][\"Genre\"] == genre, \"Weight\"] = map_to_rosect_wvs_scaled\n",
    "    \n",
    "    return map_to_rosect_wvs\n",
    "\n",
    "\n",
    "def plot_theme_freq_diff_vs_weight(map_to_rosect_wvs: Dict, colors: Dict, other_wvs: Optional[Dict] = None, genre_list: Dict = NEW_GENRES, common_only: bool = False):\n",
    "    for genre in genre_list:\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(30,15))\n",
    "        \n",
    "        themes = list(map_to_rosect_wvs[genre][\"Theme\"])\n",
    "        \n",
    "        if other_wvs is not None and not common_only:\n",
    "            themes = list(set(themes + list(other_wvs[genre][\"Theme\"])))\n",
    "        \n",
    "        themes.sort()\n",
    "        legend_elems = [Line2D([0], [0], marker=\"o\", color=\"white\", markerfacecolor=colors[theme], label=theme, markersize=20) for theme in themes]\n",
    "        \n",
    "        for theme in themes:\n",
    "            if theme in list(map_to_rosect_wvs[genre][\"Theme\"]):\n",
    "                map_to_rosect_wvs[genre][map_to_rosect_wvs[genre][\"Theme\"] == theme].plot(x=\"Weight\", y=\"Frequency Difference\", ax=axes, linestyle=\"none\",\n",
    "                                                                                          marker=\"o\", markersize=30, color=colors[theme], alpha=0.9)\n",
    "            if other_wvs is not None:\n",
    "                fill = \"full\" if theme in list(map_to_rosect_wvs[genre][\"Theme\"]) else \"none\"\n",
    "                a = 0.9 if fill == \"full\" else 1.0\n",
    "                other_wvs[genre][other_wvs[genre][\"Theme\"] == theme].plot(x=\"Weight\", y=\"Frequency Difference\", ax=axes, linestyle=\"none\",\n",
    "                                                                          marker=\"D\", markeredgewidth=3, fillstyle=fill, markersize=30,\n",
    "                                                                          color=colors[theme], alpha=a)\n",
    "            \n",
    "        axes.set_title(genre, fontsize=32)\n",
    "        \n",
    "        top = max(map_to_rosect_wvs[genre][\"Frequency Difference\"].max(), abs(map_to_rosect_wvs[genre][\"Frequency Difference\"].min()))\n",
    "        bottom = min(-map_to_rosect_wvs[genre][\"Frequency Difference\"].max(), map_to_rosect_wvs[genre][\"Frequency Difference\"].min())\n",
    "        \n",
    "        if map_to_rosect_wvs[genre][\"Frequency Difference\"].min() > -0.05:\n",
    "            bottom = -0.05\n",
    "        \n",
    "        if other_wvs is not None:\n",
    "            top = max(top, other_wvs[genre][\"Frequency Difference\"].max(), abs(other_wvs[genre][\"Frequency Difference\"].min()))\n",
    "            bottom = min(bottom, other_wvs[genre][\"Frequency Difference\"].min())\n",
    "        \n",
    "        ymajor = 40 if top > 0.05 else 160\n",
    "        offset = 0.02 if top > 0.05 else 0.002\n",
    "        setup_axis(axes, ymin=-1, ymajor=ymajor, yminor=ymajor * 5,\n",
    "                   x_ticklabel_size=22, xlabel=\"Weight\", xlabel_size=32, xlabel_pad=30, ylabel=\"Avg Frequency Difference\",\n",
    "                   left=-0.025, right=1.025,\n",
    "                   bottom=bottom - offset,\n",
    "                   top=top + offset)\n",
    "\n",
    "        axes.axhline(linestyle=\"--\", linewidth=3, color=\"black\", alpha=0.5)\n",
    "        axes.legend(handles=legend_elems, bbox_to_anchor=(1.005, 0.95), loc=\"upper left\", fontsize=22)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_theme_freq_diff(map_to_rosect_wvs: Dict, colors: Dict, other_wvs: Optional[Dict] = None, genre_list: Dict = NEW_GENRES):\n",
    "    for genre in genre_list:\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(30,15))\n",
    "        \n",
    "        themes = list(map_to_rosect_wvs[genre][\"Theme\"])\n",
    "        legend_elems = [Patch(facecolor=\"white\", edgecolor=\"black\", label=\"Reduced Frequency Difference\")]\n",
    "        \n",
    "        top = map_to_rosect_wvs[genre][\"Frequency Difference\"].max()\n",
    "        bottom = map_to_rosect_wvs[genre][\"Frequency Difference\"].min()\n",
    "        \n",
    "        if other_wvs is not None:\n",
    "            themes = list(set(themes + list(other_wvs[genre][\"Theme\"])))\n",
    "            themes.sort()\n",
    "            positions = np.arange(0, len(themes))\n",
    "            \n",
    "            merged = pd.merge(map_to_rosect_wvs[genre], other_wvs[genre], on=[\"Genre\", \"Theme\"], how=\"outer\").fillna(0)\n",
    "            merged.rename(columns={\"Frequency Difference_x\": \"Frequency Difference (Reduced)\",\n",
    "                                   \"Frequency Difference_y\": \"Frequency Difference\",\n",
    "                                   \"Weight_x\": \"Weight (Reduced)\",\n",
    "                                   \"Weight_y\": \"Weight\"}, inplace=True)\n",
    "            \n",
    "            axes.bar(positions - 0.2, merged[\"Frequency Difference (Reduced)\"], width=0.4, color=[colors[theme] for theme in themes])\n",
    "            axes.bar(positions + 0.2, merged[\"Frequency Difference\"], width=0.4, color=[colors[theme] for theme in themes], edgecolor=\"white\", hatch=\"///\")\n",
    "            legend_elems.append(Patch(facecolor=\"white\", edgecolor=\"black\", label=\"Full Frequency Difference\", hatch=\"///\"))\n",
    "            \n",
    "            top = max(top, other_wvs[genre][\"Frequency Difference\"].max())\n",
    "            bottom = min(bottom, other_wvs[genre][\"Frequency Difference\"].min())\n",
    "            \n",
    "            plt.xticks(rotation=90)\n",
    "        \n",
    "        else:\n",
    "            themes.sort()\n",
    "            map_to_rosect_wvs[genre].plot.bar(x=\"Theme\", y=\"Frequency Difference\", ax=axes, rot=90, width=0.5, color=[colors[theme] for theme in themes])            \n",
    "            \n",
    "        axes.set_title(genre, fontsize=32)\n",
    "        \n",
    "        ymajor = 40 if (top > 0.1 or abs(bottom) > 0.1) else 80 if top > 0.05 else 160\n",
    "        offset = 0.01 if top > 0.05 else 0.002\n",
    "        setup_axis(axes, ymin=-1, ymajor=ymajor, yminor=ymajor * 5,\n",
    "                   x_ticklabels=themes,\n",
    "                   ylabel=\"Avg Frequency Difference\",\n",
    "                   bottom=bottom - offset,\n",
    "                   top=top + offset,\n",
    "                   grid=\"-\", minor_grid=\":\")\n",
    "        \n",
    "        axes.grid(axis=\"x\", linestyle=\"--\")\n",
    "\n",
    "        axes.legend(handles=legend_elems, loc=\"upper right\", fontsize=18)\n",
    "        plt.margins(x=0.025)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnrf_to_rosect_set = {genre: wnrf_to_rosect_df_scaled[wnrf_to_rosect_df_scaled[\"@Genre\"] == genre][[\"Book #\", \"@Genre\"] + [w for w in wnrf_to_rosect_rw[genre][\"Feature\"]] + [\"@Outcome\"]] for genre in NEW_GENRES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wnrf_themes_by_genre_df, wnrf_tbg_themes = get_themes_by_genre(wnrf_to_rosect_set, wnrf_to_rosect_rw)\n",
    "wnrf_to_rosect_wvs = get_rosect_freq(wnrf_to_rosect_set, wnrf_tbg_themes, wnrf_to_rosect_rw)\n",
    "colors = create_cmap(plt.cm.tab10, NEW_GENRES)\n",
    "wnrf_wvs_colors = create_cmap(plt.cm.nipy_spectral, wnrf_tbg_themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_tbg(wnrf_themes_by_genre_df, wnrf_tbg_themes, colors, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_tbg(wnrf_themes_by_genre_df, wnrf_tbg_themes, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_tbg(wnrf_themes_by_genre_df, wnrf_tbg_themes, colors, scatter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_theme_freq_diff_vs_weight(wnrf_to_rosect_wvs, wnrf_wvs_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_set = {genre: wn_df[wn_df[\"@Genre\"] == genre] for genre in NEW_GENRES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wn_to_rocat = map_to_roget(wn_set, src_model=\"WordNet\", to_categories=True)\n",
    "# with open(str(PROJ_ROOT.joinpath(\"data\", \"wn_to_rocat.txt\")), \"wb+\") as f:\n",
    "#     try:\n",
    "#         pickle.dump(wn_to_rocat, f)\n",
    "#     except MemoryError:\n",
    "#         print(\"There was a MemoryError when dumping wn_to_rocat\")\n",
    "\n",
    "wn_to_rocat = pickle.load(open(str(PROJ_ROOT.joinpath(\"data\", \"wn_to_rocat.txt\")), \"rb+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_to_rocat_no_scale, wn_to_rocat_scaled = concat_map_to_roget(wn_to_rocat, src_model=\"WordNet\", map_to=\"Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_to_rosect = map_to_roget(wn_to_rocat_no_scale, src_model=\"WordNet\", to_sections=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_to_rosect_no_scale, wn_to_rosect_scaled = concat_map_to_roget(wn_to_rosect, src_model=\"WordNet\", map_to=\"Section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_wn_to_rosect_acc, full_wn_to_rosect_weights, wn_to_rosect_acc, wn_to_rosect_weights = test_map_to_roget(wn_to_rosect_no_scale, wn_to_rosect_scaled, src_model=\"WordNet\", map_to=\"Section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_to_rosect_df_scaled = pd.concat(list(wn_to_rosect_scaled.values())).fillna(0)\n",
    "wn_to_rosect_exh, wn_to_rosect_rw = reduce_features(wn_to_rosect_weights, \"WordNet to Roget Section\", model_df=wn_to_rosect_df_scaled, og_acc=wn_to_rosect_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wn_to_rosect_reduced_acc = plot_exhausted(wn_to_rosect_exh, markersize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_to_rosect_set = {genre: wn_to_rosect_df_scaled[wn_to_rosect_df_scaled[\"@Genre\"] == genre][[\"Book #\", \"@Genre\"] + [w for w in wn_to_rosect_rw[genre][\"Feature\"]] + [\"@Outcome\"]] for genre in NEW_GENRES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_to_rosect_themes_by_genre_df, wn_to_rosect_tbg_themes = get_themes_by_genre(wn_to_rosect_set, wn_to_rosect_rw)\n",
    "wn_to_rosect_wvs = get_rosect_freq(wn_to_rosect_set, wn_to_rosect_tbg_themes, wn_to_rosect_rw)\n",
    "wn_to_rosect_wvs_colors = create_cmap(plt.cm.nipy_spectral, wn_to_rosect_tbg_themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_theme_freq_diff_vs_weight(wnrf_to_rosect_wvs, wn_to_rosect_wvs_colors, other_wvs=wn_to_rosect_wvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Plot only avg freq diff as bar chart\n",
    "plot_theme_freq_diff(wnrf_to_rosect_wvs, wn_to_rosect_wvs_colors, other_wvs=wn_to_rosect_wvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theme_diffs(wvs1: Dict, wvs2: Dict, genre_list: List = GENRES):\n",
    "    theme_diffs = {}\n",
    "    for genre in genre_list:\n",
    "        g_diff = pd.merge(wvs1[genre], wvs2[genre], on=[\"Genre\", \"Theme\"], how=\"outer\").fillna(0)\n",
    "        g_diff.rename(columns={\"Frequency Difference_x\": \"Frequency Difference (Reduced)\",\n",
    "                               \"Frequency Difference_y\": \"Frequency Difference\",\n",
    "                               \"Weight_x\": \"Weight (Reduced)\",\n",
    "                               \"Weight_y\": \"Weight\"}, inplace=True)\n",
    "        \n",
    "        error = distance(g_diff[[\"Frequency Difference (Reduced)\", \"Weight (Reduced)\"]], g_diff[[\"Frequency Difference\", \"Weight\"]])\n",
    "        theme_diffs[genre] = pd.DataFrame({\"Genre\": g_diff[\"Genre\"], \"Theme\": g_diff[\"Theme\"], \"Error\": error}).sort_values(by=[\"Theme\"])\n",
    "        theme_diffs[genre] = theme_diffs[genre].append({\"Genre\": \"Average\", \"Theme\": \"Average\", \"Error\": theme_diffs[genre][\"Error\"].mean()}, ignore_index=True)\n",
    "        \n",
    "    return theme_diffs\n",
    "\n",
    "\n",
    "def distance(df1: Union[pd.DataFrame, pd.Series], df2: Union[pd.DataFrame, pd.Series]):\n",
    "    return np.linalg.norm(df1.values - df2.values, axis=1)\n",
    "\n",
    "\n",
    "def plot_theme_diffs(theme_diffs_: Dict, colors: Dict, genre_list: List = GENRES):\n",
    "    for genre in genre_list:\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(30,15))\n",
    "        \n",
    "        theme_diffs = theme_diffs_[genre][theme_diffs_[genre][\"Genre\"] != \"Average\"].copy()\n",
    "        themes = list(theme_diffs[\"Theme\"])\n",
    "        \n",
    "        theme_diffs.plot.bar(x=\"Theme\", y=\"Error\", ax=axes, width=0.5, rot=90, color=[colors[theme] for theme in themes])\n",
    "            \n",
    "        axes.set_title(genre, fontsize=32)\n",
    "        ymajor=10 if theme_diffs[\"Error\"].max() > 0.7 else 20\n",
    "        setup_axis(axes, ymajor=ymajor, yminor=ymajor * 4,\n",
    "                   x_ticklabels=themes, ylabel=\"No Reduction Theme Error\",\n",
    "                   top=theme_diffs[\"Error\"].max() + 0.02,\n",
    "                   grid=\"-\", minor_grid=\":\")\n",
    "        \n",
    "        axes.grid(axis=\"x\", linestyle=\"none\")\n",
    "        axes.get_legend().remove()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_to_rosect_theme_diffs = get_theme_diffs(wnrf_to_rosect_wvs, wn_to_rosect_wvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in GENRES:\n",
    "    display_df(wn_to_rosect_theme_diffs[genre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 250\n",
    "\n",
    "plot_theme_diffs(wn_to_rosect_theme_diffs, wn_to_rosect_wvs_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping Roget to Roget Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roget_df = pd.DataFrame(roget_data).fillna(0).rename(columns={\"_genre\": \"@Genre\", \"_outcome\": \"@Outcome\"})\n",
    "roget_df.insert(0, \"Book #\", unigram_df[\"Book #\"].reset_index(drop=True))\n",
    "roget_rf_set = {genre: roget_df[roget_df[\"@Genre\"] == genre][[\"Book #\", \"@Genre\"] + [w for w in roget_rw[genre][\"Feature\"]] + [\"@Outcome\"]] for genre in GENRES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roget_rf_to_rosect = map_to_roget(roget_rf_set, src_model=\"Roget\", to_sections=True)\n",
    "rosect_rf_no_scale, rosect_rf_scaled = concat_map_to_roget(roget_rf_to_rosect, src_model=\"Roget\", map_to=\"Section\")\n",
    "full_rosect_rf_acc, full_rosect_rf_weights, rosect_rf_acc, rosect_rf_weights = test_map_to_roget(rosect_rf_no_scale, rosect_rf_scaled, src_model=\"Roget\", map_to=\"Section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_rf_df_scaled = pd.concat(list(rosect_rf_scaled.values())).fillna(0)\n",
    "rosect_rf_exh, rosect_rf_rw = reduce_features(rosect_rf_weights, \"Roget Section\", model_df=rosect_rf_df_scaled, og_acc=rosect_rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rosect_rf_reduced_acc = plot_exhausted(rosect_rf_exh, markersize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_rf_set = {genre: rosect_rf_df_scaled[rosect_rf_df_scaled[\"@Genre\"] == genre][[\"Book #\", \"@Genre\"] + [w for w in rosect_rf_rw[genre][\"Feature\"]] + [\"@Outcome\"]] for genre in GENRES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_rf_themes_by_genre_df, rosect_rf_tbg_themes = get_themes_by_genre(rosect_rf_set, rosect_rf_rw)\n",
    "rosect_rf_wvs = get_rosect_freq(rosect_rf_set, rosect_rf_tbg_themes, rosect_rf_rw)\n",
    "rosect_rf_wvs_colors = create_cmap(plt.cm.nipy_spectral, rosect_rf_tbg_themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_theme_freq_diff_vs_weight(rosect_rf_wvs, rosect_rf_wvs_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genre Prediction - One v. One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wn_genre_acc, wn_genre_weights = predict_genre(wordnet_df_scaled, \"WordNet\", how=\"one_v_one\", disp_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wn_genre_exh, wn_genre_rw = reduce_features(wn_genre_weights, \"WordNet\", max_steps=15, genre_list=GENRE_COMBS, g_predict=\"one_v_one\", og_acc=wn_genre_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_clf_colors = create_cmap(plt.cm.nipy_spectral, GENRE_COMBS)\n",
    "wn_genre_reduced_acc = plot_exhausted(wn_genre_exh, max_steps=15, genre_list=GENRE_COMBS, colors=g_clf_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenresNumsOutcomes = {(g1, g2): wn_df[(wn_df[\"@Genre\"] == g1) | (wn_df[\"@Genre\"] == g2)][[\"Book #\", \"@Genre\" ,\"@Outcome\"]].reset_index(drop=True) for g1, g2 in GENRE_COMBS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roget_genre_acc, roget_genre_weights = predict_genre(roget_df_scaled, \"Roget\", how=\"one_v_one\", disp_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roget_g_set = {(g1, g2): roget_df[(roget_df[\"@Genre\"] == g1) | (roget_df[\"@Genre\"] == g2)] for g1, g2 in GENRE_COMBS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roget_g_to_rosect = pickle.load(open(str(PROJ_ROOT.joinpath(\"data\", \"roget_g_to_rosect.txt\")), \"rb+\"))\n",
    "\n",
    "# roget_g_to_rosect = map_to_roget(roget_g_set, src_model=\"Roget\", to_sections=True, genre_list=GENRE_COMBS)\n",
    "# with open(str(PROJ_ROOT.joinpath(\"data\", \"roget_g_to_rosect.txt\")), \"wb+\") as f:\n",
    "#     try:\n",
    "#         pickle.dump(roget_g_to_rosect, f)\n",
    "#     except MemoryError:\n",
    "#         print(\"There was a MemoryError when dumping roget_g_to_rosect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_g_no_scale, rosect_g_scaled = concat_map_to_roget(roget_g_to_rosect, src_model=\"Roget\", map_to=\"Section\", genre_list=GENRE_COMBS, nums_outcomes=GenresNumsOutcomes)\n",
    "full_rosect_g_acc, full_rosect_g_weights, rosect_g_acc, rosect_g_weights = test_map_to_roget(rosect_g_no_scale, rosect_g_scaled,\n",
    "                                                                                             src_model=\"Roget\", map_to=\"Section\",\n",
    "                                                                                             genre_list=GENRE_COMBS, g_predict=\"one_v_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK WHICH IS BETTER FIRST\n",
    "rosect_g_df = pd.concat(list(rosect_g_no_scale.values())).fillna(0)\n",
    "rosect_g_df_scaled, _ = process_and_scale(rosect_g_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_g_set = {(g1, g2): rosect_g_df_scaled[(rosect_g_df_scaled[\"@Genre\"] == g1) | (rosect_g_df_scaled[\"@Genre\"] == g2)] for g1, g2 in GENRE_COMBS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_g_themes_by_genre_df, rosect_g_tbg_themes = get_themes_by_genre(rosect_g_set, full_rosect_g_weights, genre_list=GENRE_COMBS)\n",
    "rosect_g_wvg = get_rosect_freq(rosect_g_set, rosect_g_tbg_themes, full_rosect_g_weights, genre_list=GENRE_COMBS, g_predict=\"one_v_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roget_genre_exh, roget_genre_rw = reduce_features(roget_genre_weights, \"Roget\", genre_list=GENRE_COMBS, g_predict=\"one_v_one\", og_acc=roget_genre_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roget_genre_reduced_acc = plot_exhausted(roget_genre_exh, genre_list=GENRE_COMBS, colors=g_clf_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roget_grf_set = {(g1, g2): roget_df[(roget_df[\"@Genre\"] == g1) | (roget_df[\"@Genre\"] == g2)][[\"Book #\", \"@Genre\"] + [w for w in roget_genre_rw[(g1, g2)][\"Feature\"]] + [\"@Outcome\"]] for g1, g2 in GENRE_COMBS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roget_grf_to_rosect = map_to_roget(roget_grf_set, src_model=\"Roget\", to_sections=True, genre_list=GENRE_COMBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rosect_grf_no_scale, rosect_grf_scaled = concat_map_to_roget(roget_grf_to_rosect, src_model=\"Roget\", map_to=\"Section\", genre_list=GENRE_COMBS, nums_outcomes=GenresNumsOutcomes)\n",
    "full_rosect_grf_acc, full_rosect_grf_weights, rosect_grf_acc, rosect_grf_weights = test_map_to_roget(rosect_grf_no_scale, rosect_grf_scaled,\n",
    "                                                                                                     src_model=\"Roget\", map_to=\"Section\",\n",
    "                                                                                                     genre_list=GENRE_COMBS, g_predict=\"one_v_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rosect_grf_df = pd.concat(list(rosect_grf_no_scale.values())).fillna(0)\n",
    "rosect_grf_df_scaled, _ = process_and_scale(rosect_grf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rosect_grf_exh, rosect_grf_rw = reduce_features(full_rosect_grf_weights, \"Roget Section\", model_df=rosect_grf_df_scaled,\n",
    "                                                genre_list=GENRE_COMBS, g_predict=\"one_v_one\", og_acc=full_rosect_grf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rosect_grf_reduced_acc = plot_exhausted(rosect_grf_exh, genre_list=GENRE_COMBS, colors=g_clf_colors, markers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_grf_set = {(g1, g2): rosect_grf_df_scaled[(rosect_grf_df_scaled[\"@Genre\"] == g1) | (rosect_grf_df_scaled[\"@Genre\"] == g2)][[\"Book #\", \"@Genre\"] + [w for w in rosect_grf_rw[(g1, g2)][\"Feature\"]] + [\"@Outcome\"]] for g1, g2 in GENRE_COMBS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rosect_grf_themes_by_genre_df, rosect_grf_tbg_themes = get_themes_by_genre(rosect_grf_set, rosect_grf_rw, genre_list=GENRE_COMBS)\n",
    "rosect_grf_wvg = get_rosect_freq(rosect_grf_set, rosect_grf_tbg_themes, rosect_grf_rw, genre_list=GENRE_COMBS, g_predict=\"one_v_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "plot_theme_freq_diff_vs_weight(rosect_grf_wvg, rosect_rf_wvs_colors, genre_list=GENRE_COMBS, other_wvs=rosect_g_wvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rosect_genre_theme_diffs = get_theme_diffs(rosect_grf_wvg, rosect_g_wvg, genre_list=GENRE_COMBS)\n",
    "# genre_similarities = []\n",
    "# for comb in GENRE_COMBS:\n",
    "#     similarity = rosect_grf_wvg[comb][\"Frequency Difference\"].mean()\n",
    "#     genre_similarities.append({\"Genre\": comb, \"Similarity\": abs(similarity)})\n",
    "\n",
    "# genre_sims_df = pd.DataFrame(genre_similarities).sort_values(by=[\"Similarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 250\n",
    "\n",
    "plot_theme_diffs(rosect_genre_theme_diffs, rosect_rf_wvs_colors, genre_list=GENRE_COMBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rosect_genre_wvgs = get_rosect_freq(rosect_grf_set, rosect_grf_tbg_themes, rosect_genre_rw, genre_list=GENRE_COMBS, g_predict=True, g_success=True)\n",
    "# plot_theme_freq_diff_vs_weight(rosect_genre_wvgs, rosect_rf_wvs_colors, genre_list=GENRE_COMBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre Prediction - One v. All"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: For each genre, do genre prediciton of selected genre vs. not the selected genre\n",
    "#           - Pick n random books from selected genre, and n random books from all other genres --> use kfold\n",
    "#           - Predict if book is of selected genre or not\n",
    "\n",
    "roget_set = {genre: roget_df[roget_df[\"@Genre\"] == genre] for genre in GENRES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roget_ova_acc, roget_ova_weights = predict_genre(roget_df_scaled, \"Roget\", how=\"one_v_all\", genre_list=GENRES, disp_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roget_ova_exh, roget_ova_rw = reduce_features(roget_ova_weights, \"Roget\", g_predict=\"one_v_all\", og_acc=roget_ova_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roget_genre_reduced_acc = plot_exhausted(roget_ova_exh, markersize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roget_to_rosect = pickle.load(open(str(PROJ_ROOT.joinpath(\"data\", \"roget_to_rosect.txt\")), \"rb+\"))\n",
    "# roget_to_rosect = map_to_roget(roget_set, src_model=\"Roget\", to_sections=True)\n",
    "# with open(str(PROJ_ROOT.joinpath(\"data\", \"roget_to_rosect.txt\")), \"wb+\") as f:\n",
    "#     try:\n",
    "#         pickle.dump(roget_to_rosect, f)\n",
    "#     except MemoryError:\n",
    "#         print(\"There was a MemoryError when dumping roget_to_rosect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rosect_ova_no_scale, rosect_ova_scaled = concat_map_to_roget(roget_to_rosect, src_model=\"Roget\", map_to=\"Section\")\n",
    "full_rosect_ova_acc, full_rosect_ova_weights, rosect_ova_acc, rosect_ova_weights = test_map_to_roget(rosect_ova_no_scale, rosect_ova_scaled,\n",
    "                                                                                                     src_model=\"Roget\", map_to=\"Section\",\n",
    "                                                                                                     g_predict=\"one_v_all\")\n",
    "\n",
    "# TODO: Is scaling each genre independently cheating? Why does rosect scaled by genre perform better than reduced roget? (same goes for WordNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_ova_df = pd.concat(list(rosect_ova_no_scale.values())).fillna(0)\n",
    "rosect_ova_df_scaled, _ = process_and_scale(rosect_ova_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_ova_set = {genre: rosect_ova_df_scaled[rosect_ova_df_scaled[\"@Genre\"] == genre] for genre in GENRES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_ova_themes_by_genre_df, rosect_ova_tbg_themes = get_themes_by_genre(rosect_ova_set, full_rosect_ova_weights)\n",
    "rosect_ova_wvg = get_rosect_freq(rosect_ova_set, rosect_ova_tbg_themes, full_rosect_ova_weights, g_predict=\"one_v_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roget_ovarf_set = {genre: roget_df[roget_df[\"@Genre\"] == genre][[\"Book #\", \"@Genre\"] + [w for w in roget_ova_rw[genre][\"Feature\"]] + [\"@Outcome\"]] for genre in GENRES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roget_ovarf_to_rosect = map_to_roget(roget_ovarf_set, src_model=\"Roget\", to_sections=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rosect_ovarf_no_scale, rosect_ovarf_scaled = concat_map_to_roget(roget_ovarf_to_rosect, src_model=\"Roget\", map_to=\"Section\")\n",
    "full_rosect_ovarf_acc, full_rosect_ovarf_weights, rosect_ovarf_acc, rosect_ovarf_weights = test_map_to_roget(rosect_ovarf_no_scale, rosect_ovarf_scaled,\n",
    "                                                                                                             src_model=\"Roget\", map_to=\"Section\",\n",
    "                                                                                                             g_predict=\"one_v_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_ovarf_df = pd.concat(list(rosect_ovarf_no_scale.values())).fillna(0)\n",
    "rosect_ovarf_df_scaled, _ = process_and_scale(rosect_ovarf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_ovarf_exh, rosect_ovarf_rw = reduce_features(rosect_ovarf_weights, \"Roget Section\", model_df=rosect_ovarf_df_scaled,\n",
    "                                                    g_predict=\"one_v_all\", og_acc=rosect_ovarf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rosect_ovarf_reduced_acc = plot_exhausted(rosect_ovarf_exh, markersize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_ovarf_set = {genre: rosect_ovarf_df_scaled[rosect_ovarf_df_scaled[\"@Genre\"] == genre][[\"Book #\", \"@Genre\"] + [w for w in rosect_ovarf_rw[genre][\"Feature\"]] + [\"@Outcome\"]] for genre in GENRES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosect_ovarf_themes_by_genre_df, rosect_ovarf_tbg_themes = get_themes_by_genre(rosect_ovarf_set, rosect_ovarf_rw)\n",
    "rosect_ovarf_wvg = get_rosect_freq(rosect_ovarf_set, rosect_ovarf_tbg_themes, rosect_ovarf_rw, g_predict=\"one_v_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 100\n",
    "plot_theme_freq_diff(rosect_ovarf_wvg, rosect_rf_wvs_colors, other_wvs=rosect_ova_wvg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wn_ova_acc, wn_ova_weights = predict_genre(wordnet_df_scaled, \"WordNet\", how=\"one_v_all\", genre_list=GENRES, disp_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_ova_exh, wn_ova_rw = reduce_features(wn_ova_weights, \"WordNet\", max_steps=15, g_predict=\"one_v_all\", og_acc=wn_ova_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wn_ova_reduced_acc = plot_exhausted(wn_ova_exh, max_steps=15, markersize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_wn_rosect_ova_acc, full_wn_rosect_ova_weights, wn_rosect_ova_acc, wn_rosect_ova_weights = test_map_to_roget(wn_to_rosect_no_scale, wn_to_rosect_scaled,\n",
    "                                                                                                                 src_model=\"WordNet\", map_to=\"Section\",\n",
    "                                                                                                                 g_predict=\"one_v_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_rosect_ova_df = pd.concat(list(wn_to_rosect_no_scale.values())).fillna(0)\n",
    "wn_rosect_ova_df_scaled, _ = process_and_scale(wn_rosect_ova_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_rosect_ova_set = {genre: wn_rosect_ova_df_scaled[wn_rosect_ova_df_scaled[\"@Genre\"] == genre] for genre in GENRES}\n",
    "\n",
    "wn_rosect_ova_themes_by_genre_df, wn_rosect_ova_tbg_themes = get_themes_by_genre(wn_rosect_ova_set, wn_rosect_ova_weights)\n",
    "wn_rosect_ova_wvg = get_rosect_freq(wn_rosect_ova_set, wn_rosect_ova_tbg_themes, wn_rosect_ova_weights, g_predict=\"one_v_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_freq_diff_by_genre(map_to_rosect_wvs: Dict, colors: Dict, other_wvs: Optional[Dict] = None, genre_list: Dict = GENRES, **kwargs):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(30,15))\n",
    "    \n",
    "    avg_freq_diffs = pd.DataFrame([{\"Genre\": genre, \"Average Frequency Difference\": map_to_rosect_wvs[genre][\"Frequency Difference\"].abs().mean()} for genre in genre_list])\n",
    "\n",
    "    legend_elems = [Patch(facecolor=\"white\", edgecolor=\"black\", label=\"Reduced Average Frequency Difference\")]\n",
    "\n",
    "    top = avg_freq_diffs[\"Average Frequency Difference\"].max()\n",
    "    bottom = avg_freq_diffs[\"Average Frequency Difference\"].min()\n",
    "\n",
    "    if other_wvs is not None:\n",
    "        other_avg_freq_diffs = pd.DataFrame([{\"Genre\": genre, \"Average Frequency Difference\": other_wvs[genre][\"Frequency Difference\"].abs().mean()} for genre in genre_list])\n",
    "        positions = np.arange(0, len(genre_list))\n",
    "\n",
    "        merged = pd.merge(avg_freq_diffs, other_avg_freq_diffs, on=\"Genre\", how=\"outer\").fillna(0)\n",
    "        merged.rename(columns={\"Average Frequency Difference_x\": \"Average Frequency Difference (Reduced)\",\n",
    "                               \"Average Frequency Difference_y\": \"Average Frequency Difference\"}, inplace=True)\n",
    "\n",
    "        axes.bar(positions - 0.2, merged[\"Average Frequency Difference (Reduced)\"], width=0.4, color=[colors[genre] for genre in genre_list])\n",
    "        axes.bar(positions + 0.2, merged[\"Average Frequency Difference\"], width=0.4, color=[colors[genre] for genre in genre_list], edgecolor=\"white\", hatch=\"///\")\n",
    "        legend_elems.append(Patch(facecolor=\"white\", edgecolor=\"black\", label=\"Full Average Frequency Difference\", hatch=\"///\"))\n",
    "\n",
    "        top = max(top, other_avg_freq_diffs[\"Average Frequency Difference\"].max())\n",
    "        bottom = min(bottom, other_avg_freq_diffs[\"Average Frequency Difference\"].min())\n",
    "\n",
    "        plt.xticks(rotation=90)\n",
    "        display_df(merged.append({\"Genre\": \"Average\",\n",
    "                                  \"Average Frequency Difference (Reduced)\": merged[\"Average Frequency Difference (Reduced)\"].mean(),\n",
    "                                  \"Average Frequency Difference\": merged[\"Average Frequency Difference\"].mean()}, ignore_index=True))\n",
    "\n",
    "    else:\n",
    "        avg_freq_diffs.plot.bar(x=\"Genre\", y=\"Average Frequency Difference\", ax=axes, rot=90, width=0.5, color=[colors[genre] for genre in genre_list])\n",
    "        display_df(merged.append({\"Genre\": \"Average\", \"Average Frequency Difference\": avg_freq_diffs[\"Average Frequency Difference\"].mean()}, ignore_index=True))\n",
    "\n",
    "    ymajor = 40 if (top > 0.1 or abs(bottom) > 0.1) else 80 if top > 0.05 else 160\n",
    "    offset = 0.01 if top > 0.05 else 0.002\n",
    "    setup_axis(axes, ymin=-1, ymajor=ymajor, yminor=ymajor * 5,\n",
    "               x_ticklabels=genre_list,\n",
    "               ylabel=\"Magnitude of Avg Frequency Difference\",\n",
    "               bottom=bottom - offset,\n",
    "               top=top + offset,\n",
    "               grid=\"-\", minor_grid=\":\")\n",
    "\n",
    "    axes.set_title(kwargs.get(\"title\", \"\"), fontsize=32)\n",
    "    axes.grid(axis=\"x\", linestyle=\"--\")\n",
    "\n",
    "    axes.legend(handles=legend_elems, loc=\"upper right\", fontsize=18)\n",
    "    plt.margins(x=0.025)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: What makes the reduced word list special? How is it able to achieve such high performance?\n",
    "#           - Magnitude of the avg freq diff should be larger for reduced feature set\n",
    "\n",
    "plot_avg_freq_diff_by_genre(wnrf_to_rosect_wvs, colors, other_wvs=wn_to_rosect_wvs, title=\"Magnitude of Average Freq. Diff. of Themes by Genre - Success Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg_freq_diff_by_genre(rosect_ovarf_wvg, colors, other_wvs=rosect_ova_wvg, title=\"Magnitude of Average Freq. Diff. of Themes by Genre - Genre Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 500\n",
    "\n",
    "def score_books(model_dict: Dict, model_weights: Dict, weight_name: str):\n",
    "    scores = {}\n",
    "    bar_length = sum(len(model_dict[genre].columns) - 3 for genre in GENRES)\n",
    "\n",
    "    display(HTML(f\"<h4>Scoring books with {weight_name} Feature Weights...</h4>\"))\n",
    "    with tqdm(total=bar_length) as pbar:\n",
    "        for genre in GENRES:\n",
    "            pbar.set_postfix_str(f\" -- {genre}\")\n",
    "            for col in model_dict[genre].drop(columns=[\"Book #\", \"@Genre\", \"@Outcome\"]).columns:\n",
    "                weight = model_weights[genre][model_weights[genre][\"Feature\"] == col][\"Weight\"].values[0]\n",
    "                model_dict[genre][col] *= weight\n",
    "                pbar.update(1)\n",
    "            g_scores = model_dict[genre].drop(columns=[\"Book #\", \"@Genre\", \"@Outcome\"]).sum(axis=1).reset_index(drop=True)\n",
    "            scores[genre] = pd.DataFrame({\"Book #\": model_dict[genre][\"Book #\"].reset_index(drop=True), \"Genre\": model_dict[genre][\"@Genre\"].reset_index(drop=True), \"WordNet Score\": g_scores, \"Outcome\": model_dict[genre][\"@Outcome\"].reset_index(drop=True)})\n",
    "            scores[genre][\"WordNet Score\"] = scale.fit_transform(scores[genre][[\"WordNet Score\"]])\n",
    "            scores[genre].sort_values(by=[\"WordNet Score\"], ascending=False, inplace=True)\n",
    "            scores[genre] = scores[genre].reset_index(drop=True).reset_index().rename(columns={\"index\": \"Rank\"})[[\"Book #\", \"Genre\", \"Rank\", \"WordNet Score\", \"Outcome\"]]\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def get_precision(scores: Dict, display_scores: bool = False):\n",
    "    score_pre = []\n",
    "    for genre in GENRES:\n",
    "        if display_scores:\n",
    "            display(HTML(f\"<b>{genre} Scores<b>\"))\n",
    "            display_df(scores[genre], max_rows=16)\n",
    "        num_success = len(scores[genre][scores[genre][\"Outcome\"] == \"SUCCESSFUL\"])\n",
    "        top = scores[genre].head(num_success)\n",
    "        pre = len(top[top[\"Outcome\"] == \"SUCCESSFUL\"]) / num_success\n",
    "        score_pre.append({\"Genre\": genre, \"Pre\": pre})\n",
    "    score_pre_df = pd.DataFrame(score_pre)\n",
    "    return score_pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_rf_scaled = {genre: wordnet_df_scaled[wordnet_df_scaled[\"@Genre\"] == genre][[\"Book #\", \"@Genre\"] + [w for w in wn_rw[genre][\"Feature\"]] + [\"@Outcome\"]] for genre in GENRES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_scores = score_books(wn_rf_scaled, wn_rw, \"Reduced WordNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wn_score_pre_df = get_precision(wn_scores, display_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df(wn_score_pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Compare reduced word lists of each genre --> how are they similar/different?\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def get_genre_intersections(model_weights: Dict, display: bool = False):\n",
    "    intersections = {}\n",
    "\n",
    "    for g1, g2 in GENRE_COMBS:\n",
    "        intersections[(g1, g2)] = pd.merge(model_weights[g1], model_weights[g2], on=\"Feature\")\n",
    "        intersections[(g1, g2)].columns = [\"Feature\"] + [g1, g2]\n",
    "\n",
    "        g1_scaled = scale.fit_transform(intersections[(g1, g2)][[g1]].abs())\n",
    "        intersections[(g1, g2)][g1] = g1_scaled\n",
    "        g2_scaled = scale.fit_transform(intersections[(g1, g2)][[g2]].abs())\n",
    "        intersections[(g1, g2)][g2] = g2_scaled\n",
    "\n",
    "        intersections[(g1, g2)][\"Difference\"] = intersections[(g1, g2)][g1] - intersections[(g1, g2)][g2]\n",
    "        intersections[(g1, g2)].sort_values(by=[g1], ascending=False, inplace=True)\n",
    "        \n",
    "        if display:\n",
    "            display_df(intersections[(g1, g2)], f\"<b>{g1}, {g2} -- {len(intersections[(g1, g2)])}</b>\", max_rows=10)\n",
    "\n",
    "    return intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_intersections = get_genre_intersections(wn_rw, display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Accuracy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "UNI = {'Adventure_Stories': 84.0, \n",
    "       'Fiction': 75.0, \n",
    "       'Historical_Fiction': 60.0, \n",
    "       'Love_Stories': 82.0,\n",
    "       'Mystery': 73.0, \n",
    "       'Poetry': 71.0, \n",
    "       'Science_Fiction': 61.0, \n",
    "       'Short_Stories': 57.0}\n",
    "\n",
    "for i in UNI.keys():\n",
    "    UNI[i] = UNI[i]/100\n",
    "\n",
    "BI = {'Adventure_Stories': 81.0, \n",
    "       'Fiction': 75.0, \n",
    "       'Historical_Fiction': 51.0, \n",
    "       'Love_Stories': 72.0,\n",
    "       'Mystery': 73.0, \n",
    "       'Poetry': 72.0, \n",
    "       'Science_Fiction': 59.0, \n",
    "       'Short_Stories': 57.0}\n",
    "\n",
    "for i in BI.keys():\n",
    "    BI[i] = BI[i]/100\n",
    "\n",
    "POS = {'Adventure_Stories': 74.0, \n",
    "       'Fiction': 72.0, \n",
    "       'Historical_Fiction': 47.0, \n",
    "       'Love_Stories': 65.9,\n",
    "       'Mystery': 63.9, \n",
    "       'Poetry': 63.0, \n",
    "       'Science_Fiction': 63.0, \n",
    "       'Short_Stories': 67.0}\n",
    "\n",
    "for i in POS.keys():\n",
    "    POS[i] = POS[i]/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(30,15))\n",
    "\n",
    "all_acc_colors = create_cmap(plt.cm.tab20, ACCURACIES, as_dict=False) # [to_hex(c) for c in cycler(\"color\", plt.cm.tab20(np.linspace(0, 1, len(ACCURACIES)))).by_key()[\"color\"]]\n",
    "\n",
    "for (name, accuracies), color in zip(ACCURACIES.items(), all_acc_colors):\n",
    "    accuracies.rename(columns={\"Accuracy\": name}, inplace=True)\n",
    "    accuracies.plot(x=\"Genre\", y=name, ax=axes, rot=0, color=color, linewidth=3)\n",
    "\n",
    "axes.set_xticks(np.linspace(0, len(GENRES), len(GENRES) * 4 + 1), minor=True)    \n",
    "axes.set_xticks(np.linspace(0, len(GENRES), len(GENRES) * 2 + 1))\n",
    "axes.set_xticks(np.arange(0, len(GENRES)))\n",
    "axes.set_xticklabels(GENRES)\n",
    "\n",
    "axes.set_yticks(np.linspace(0, 1, 101), minor=True)\n",
    "axes.set_yticks(np.linspace(0, 1, 21))\n",
    "\n",
    "axes.tick_params(axis=\"x\", labelsize=20)\n",
    "axes.tick_params(axis=\"y\", labelsize=24)\n",
    "axes.set_xlabel(\"Genre\", fontsize=28, labelpad=20)\n",
    "axes.set_ylabel(\"Accuracy\", fontsize=32, labelpad=30)\n",
    "# axes.set_ylim(bottom=0.4, top=0.8)\n",
    "axes.grid(linestyle=\"--\")\n",
    "axes.grid(axis=\"y\", linestyle=\":\", which=\"minor\")\n",
    "\n",
    "\n",
    "legend = axes.legend(ACCURACIES.keys(), bbox_to_anchor=(1, 0.95), fontsize=22)\n",
    "plt.margins(x=0.01, y=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_df = []\n",
    "for k, v in ACCURACIES.items():\n",
    "    average = v.loc[v[\"Genre\"] == \"Average\", \"Accuracy\"]\n",
    "    avg_df.append({\"Model\": k, \"Avg\": average})\n",
    "\n",
    "avg_df = pd.DataFrame(avg_df)\n",
    "avg_df.sort_values(by=[\"Avg\"], ascending=False, inplace=True)\n",
    "avg_df.reset_index(drop=True, inplace=True)\n",
    "display_df(avg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reduced_accs = {\"Unigram Reduced\": uni_reduced_acc, \"Bigram Reduced\": bi_reduced_acc, \"POS Reduced\": pos_reduced_acc, \n",
    "                \"Roget Reduced\": roget_reduced_acc, \"WordNet Reduced\": wn_reduced_acc, \"LIWC Reduced\": liwc_reduced_acc}\n",
    "\n",
    "comparison_colors = create_cmap(plt.cm.tab10, reduced_accs, as_dict=False) # [to_hex(c) for c in cycler(\"color\", plt.cm.tab10(np.linspace(0, len(reduced_accs)))).by_key()[\"color\"]]\n",
    "\n",
    "originals = {k.split()[0]: ACCURACIES[k.split()[0]] for k in reduced_accs.keys()}\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(30,15))\n",
    "\n",
    "for (name, accuracies), m, c in zip(reduced_accs.items(), markers[:len(reduced_accs)], comparison_colors):\n",
    "    accuracies.plot(x=\"Genre\", y=\"Accuracy\", ax=axes, rot=0, color=c, marker=m, markersize=20, markeredgewidth=3, fillstyle=\"none\", linewidth=3, label=name)\n",
    "\n",
    "for (name, accuracies), m, c in zip(originals.items(), markers[:len(originals)], comparison_colors):\n",
    "    accuracies.rename(columns={\"Accuracy\": name}, inplace=True)\n",
    "    accuracies.plot(x=\"Genre\", y=name, ax=axes, rot=0, color=c, marker=m, markersize=20, markeredgewidth=2, fillstyle=\"none\", linewidth=2, alpha=0.5)\n",
    "\n",
    "axes.set_xticks(np.linspace(0, len(GENRES), len(GENRES) * 4 + 1), minor=True)\n",
    "axes.set_xticks(np.linspace(0, len(GENRES), len(GENRES) * 2 + 1))\n",
    "axes.set_xticks(np.arange(0, len(GENRES)))\n",
    "axes.set_xticklabels(GENRES)\n",
    "\n",
    "axes.set_yticks(np.linspace(0, 1, 101), minor=True)\n",
    "axes.set_yticks(np.linspace(0, 1, 21))\n",
    "\n",
    "axes.tick_params(axis=\"x\", labelsize=20)\n",
    "axes.tick_params(axis=\"y\", labelsize=24)\n",
    "axes.set_xlabel(\"Genre\", fontsize=28, labelpad=20)\n",
    "axes.set_ylabel(\"Accuracy\", fontsize=32, labelpad=30)\n",
    "axes.grid(linestyle=\"--\")\n",
    "\n",
    "legend = axes.legend(list(reduced_accs.keys()) + list(originals.keys()), bbox_to_anchor=(1, 1.27), fontsize=22, ncol=2)\n",
    "plt.margins(x=0.01, y=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_avg_df = []\n",
    "for name, accuracies in reduced_accs.items():\n",
    "    average = accuracies[\"Accuracy\"].sum() / 8\n",
    "    reduced_avg_df.append({\"Model\": name, \"Avg\": average})\n",
    "\n",
    "reduced_avg_df = pd.DataFrame(reduced_avg_df)\n",
    "reduced_avg_df.sort_values(by=[\"Avg\"], ascending=False, inplace=True)\n",
    "reduced_avg_df.reset_index(drop=True, inplace=True)\n",
    "display_df(reduced_avg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uni_wn_weights = {}\n",
    "uni_wn_corr = {}\n",
    "for genre in GENRES:\n",
    "    uni_wn_weights[genre] = uni_weights[genre].merge(wordnet_weights[genre], how=\"inner\", on=\"Feature\")\n",
    "    uni_wn_weights[genre].rename(columns={\"Weight_x\": \"Unigram\", \"Weight_y\": \"WordNet\"}, inplace=True)\n",
    "    \n",
    "    uni_wn_weights[genre].sort_values(by=[\"Unigram\"], ascending=False, inplace=True)\n",
    "    corr = uni_wn_weights[genre][\"Unigram\"].corr(uni_wn_weights[genre][\"WordNet\"])\n",
    "    corr = \"{0:.3f}\".format(corr)\n",
    "    display_df(uni_wn_weights[genre], f\"<h4>Unigram-WordNet Intersecting Feature Weights - {genre}</h4>\"\n",
    "                                      f\"{genre} Correlation: {corr}\", 10, True)\n",
    "        \n",
    "    csv = open(str(PROJ_ROOT.joinpath(\"data\", f\"{genre}_uni_wn_weights.csv\")), \"w+\", newline=\"\")\n",
    "    uni_wn_weights[genre].to_csv(csv, index=False)\n",
    "    csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wordnet_all_weights = []\n",
    "for genre in GENRES:\n",
    "    wordnet_genre_weights = wordnet_weights[genre].drop(columns=[\"Feature\"])\n",
    "    wordnet_genre_weights[\"Genre\"] = genre\n",
    "    wordnet_all_weights.append(wordnet_genre_weights)\n",
    "\n",
    "wordnet_all_weights = pd.concat(wordnet_all_weights)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "wordnet_all_weights[\"Genre\"] = le.fit_transform(wordnet_all_weights[\"Genre\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "WEIGHTS = {\"Unigram\": uni_weights,\n",
    "           \"Roget\": roget_weights,\n",
    "           \"POS\": pos_weights,\n",
    "           \"WordNet\": wordnet_weights,\n",
    "           \"SentiWordNet\": swn_weights,\n",
    "           \"NRC Sentiment Emotion Lexicons\": nrc_weights}\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(WEIGHTS), figsize=(20, 10))\n",
    "\n",
    "for i, ((name, weights), genre) in enumerate(zip(WEIGHTS.items(), GENRES)):\n",
    "    # csv = open(PROJ_ROOT.joinpath(\"data\", f\"{name}_weights.csv\"), \"w+\", newline=\"\")\n",
    "    # list(weights.values())[0].to_csv(csv, header=False)\n",
    "    list(weights.values())[0].head(10).plot(ax=axes[i], title=name, kind=\"bar\", rot=60, width=0.7, colormap=plt.cm.tab20)\n",
    "\n",
    "axes[0].set_ylabel(\"Weight\", labelpad=20, fontsize=16)\n",
    "\n",
    "setup(axes[0])\n",
    "setup(axes[1])\n",
    "setup(axes[2])\n",
    "setup(axes[3])\n",
    "setup(axes[4])\n",
    "setup(axes[5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(list(roget_acc.values()), label = 'roget section accuracy',linewidth=4)\n",
    "ax.legend(loc='best')\n",
    "plt.xticks(range(8), roget_df_scaled._genre.unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(list(roget_acc.values()), label = 'roget section accuracy',linewidth=4)\n",
    "ax.legend(loc='best')\n",
    "plt.xticks(range(8), roget_df_scaled._genre.unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
